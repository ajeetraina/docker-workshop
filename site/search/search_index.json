{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Welcome to Docker GenAI Workshop","text":""},{"location":"#github-sources","title":"GitHub Sources","text":"<p>The source code for this workshop is available here</p> <ul> <li>Ajeet Singh Raina - DevRel @Docker</li> </ul>"},{"location":"#benefits-of-this-docker-workshop","title":"Benefits of this Docker Workshop","text":"<ul> <li>Learn about Docker Model Runner</li> <li>Learn how to get started with Model Runner CLI</li> <li>Learn how to build GenAI Chatbot using Docker Model Runner</li> <li>Learn how to use Docker MCP Catalog and Toolkit</li> </ul>"},{"location":"lab1/best-practices/","title":"Best practices","text":""},{"location":"lab1/best-practices/#1-use-explicit-base-image-reference-instead-of-the-latest","title":"1. Use explicit base image reference instead of the latest","text":"<p>Developers are often led to believe that specifying the latest tag will provide them with the most recent image in the repository but it has some side effects.</p> <p>Image tags are mutable, meaning a publisher can update a tag to point to a new image. For example, if you specify FROM node:latest in your Dockerfile, it might resolve to the latest patch version for 18.11. However, if you rebuild the image 3 months later, the same tag might point to a different version, such as 18.13. This could result in breaking changes, and it means you also don't have an audit trail of the exact image versions that you're using.. </p> <p></p>"},{"location":"lab1/best-practices/#2-prefer-leaner-docker-images","title":"2. Prefer leaner Docker Images","text":"<p>Using leaner Docker images can help reduce the size of the final image, which can lead to faster build times, smaller storage footprint, and quicker deployment times.</p> <p>For example, try to use Slimmer Images. Select smaller images for your FROM instructions in your Dockerfile. For example, the `node:16.17.0-slim image is a minimal Docker image that provides all of the OS utilities you would expect from a Linux container. There's also the special scratch image, which contains nothing at all and is useful for creating images of statically linked binaries (source).</p> <p></p>"},{"location":"lab1/best-practices/#3-use-multi-stage-builds","title":"3. Use Multi-stage builds","text":"<p>Multi-stage builds let you reduce the size of your final image, by creating a cleaner separation between the building of your image and the final output. Split your Dockerfile instructions into distinct stages to make sure that the resulting output only contains the files that's needed to run the application.</p> <p>Using multiple stages can also let you build more efficiently by executing build steps in parallel.</p> <p></p>"},{"location":"lab1/best-practices/#4-quickly-identify-and-fix-vulnerabilities-during-the-build-time-using-docker-scout","title":"4. Quickly identify and fix vulnerabilities during the Build time using Docker Scout","text":"<p>Container images consist of layers and software packages, which are susceptible to vulnerabilities. These vulnerabilities can compromise the security of containers and applications.</p> <p>Docker Scout is a solution for proactively enhancing your software supply chain security. By analyzing your images, Docker Scout compiles an inventory of components, also known as a Software Bill of Materials (SBOM). The SBOM is matched against a continuously updated vulnerability database to pinpoint security weaknesses.</p> <p>Docker Scout image analysis is available by default for Docker Hub repositories. You can also integrate third-party registries and other services</p> <p></p>"},{"location":"lab1/best-practices/#5-add-healthcheck-in-dockerfile-and-docker-compose","title":"5. Add Healthcheck in Dockerfile and Docker Compose","text":"<p>You can add a healthcheck in both Dockerfile and Docker Compose file. In a Dockerfile, you can use the HEALTHCHECK instruction. Here's an example:</p> <pre><code>HEALTHCHECK --interval=5m --timeout=3s \\\n  CMD curl -f http://localhost/ || exit 1\n</code></pre> <p>In this example, Docker will check every five minutes if a web-server is able to serve the site's main page within three seconds. If the command (curl -f http://localhost/ || exit 1) returns a non-zero code, the container is considered unhealthy (source).</p> <p>In a Docker Compose file, you can use the healthcheck attribute under a service. Here's an example:</p> <pre><code>services:\n  web:\n    healthcheck:\n      test: [\"CMD\", \"curl\", \"-f\", \"http://localhost\"]\n      interval: 1m30s\n      timeout: 10s\n      retries: 3\n</code></pre> <p>In this example, Docker Compose will run the command curl -f http://localhost to check the health of the web service. It will do this every 1 minute and 30 seconds, and if the command doesn't return within 10 seconds or if it fails 3 times in a row, the service is considered unhealthy (source).</p>"},{"location":"lab1/best-practices/#6-use-dockerignore","title":"6. Use .dockerignore","text":"<p>The .dockerignore file is used to exclude files and directories from the build context when building a Docker image. This can help to improve build speed and avoid sending unwanted files to the Docker builder. The syntax of the .dockerignore file is similar to the .gitignore file, with each line representing a pattern that matches files and directories to be excluded.</p> <p>Here's an example of a .dockerignore file:</p> <pre><code># .dockerignore\nnode_modules\nbar\n</code></pre> <p>In this example, the node_modules directory and any file or directory named bar are excluded from the build context.</p> <p>When you run a build command, Docker looks for a .dockerignore file in the root directory of the context. If this file exists, the files and directories that match patterns in the file are removed from the build context before it's sent to the builder. If you have multiple Dockerfiles, you can use different .dockerignore files for each Dockerfile by using a special naming convention. You should place your .dockerignore file in the same directory as the Dockerfile, and prefix the .dockerignore file with the name of the Dockerfile. For example, for a Dockerfile named myapp.Dockerfile, you would create a .dockerignore file named myapp.Dockerfile.dockerignore.</p> <pre><code>.\n\u251c\u2500\u2500 index.ts\n\u251c\u2500\u2500 src/\n\u251c\u2500\u2500 docker\n\u2502   \u251c\u2500\u2500 build.Dockerfile\n\u2502   \u251c\u2500\u2500 build.Dockerfile.dockerignore\n\u2502   \u251c\u2500\u2500 lint.Dockerfile\n\u2502   \u251c\u2500\u2500 lint.Dockerfile.dockerignore\n\u2502   \u251c\u2500\u2500 test.Dockerfile\n\u2502   \u2514\u2500\u2500 test.Dockerfile.dockerignore\n\u251c\u2500\u2500 package.json\n\u2514\u2500\u2500 package-lock.json\n</code></pre> <p>In this example, each Dockerfile has its own corresponding .dockerignore file. If both a Dockerfile-specific .dockerignore file and a .dockerignore file at the root of the build context exist, the Dockerfile-specific .dockerignore file takes precedence.</p>"},{"location":"lab1/best-practices/#7-run-as-non-root-user-for-security-purpose","title":"7. Run as non-root user for security purpose","text":"<p>Running Docker as a non-root user is a good practice to mitigate potential vulnerabilities in the Docker daemon and the container runtime. Docker provides a feature called \"Rootless mode\" that allows running the Docker daemon and containers as a non-root user.</p> <p></p>"},{"location":"lab1/best-practices/#8-favour-multi-architecture-docker-images","title":"8. Favour Multi-Architecture Docker Images","text":"<p>Using multi-architecture Docker images is beneficial as it allows your Docker images to run on different hardware architectures without any modifications. This means that whether you are using an ARM-based system or an x86 machine, Docker automatically detects and selects the appropriate variant for your host's operating system and architecture.</p> <p>There are three strategies to build multi-platform images depending on your use case: - Using emulation, via QEMU support in the Linux kernel. - Building on a single builder backed by multiple nodes of different architectures. - Using a stage in your Dockerfile to cross-compile to different architectures.</p> <p>To build multi-platform images, you can use the --platform flag with the docker build command to define the target platforms for the build output, such as linux/amd64 and linux/arm64.  For example:</p> <pre><code>$ docker build --platform linux/amd64,linux/arm64 .\n</code></pre> <p>By default, Docker can build for only one platform at a time. To build for multiple platforms concurrently, you can enable the containerd image store or create a custom builder. For example, to enable the containerd image store in Docker Desktop, go to Settings and select Use containerd for pulling and storing images in the General tab. If you're not using Docker Desktop, enable the containerd image store by adding the following feature configuration to your /etc/docker/daemon.json configuration file.</p> <pre><code>{\n  \"features\": {\n    \"containerd-snapshotter\": true\n  }\n}\n</code></pre> <p>Then, restart the daemon after updating the configuration file.</p> <pre><code>$ systemctl restart docker\n</code></pre> <p></p>"},{"location":"lab1/compose-watch/","title":"Compose watch","text":"<p>Compose File Watch is a feature introduced in Docker Compose version 2.22.0. It allows for automatic updates and previews of your running Compose services as you edit and save your code. This can enable a hands-off development workflow once Compose is running, as services automatically update themselves when you save your work.</p> <pre><code>services:\n  web:\n    build: .\n    command: npm start\n    develop:\n      watch:   \n        - actions: sync\n          path: ./web\n          target: /src/web\n          ignore: \n            - node_modules/\n        - action: rebuild\n          path: package.json\n</code></pre> <p>The <code>watch</code> attribute in the Compose file defines a list of rules that control these automatic service updates based on local file changes. Each rule requires a path pattern and an action to take when a modification is detected. The action can be set to rebuild, sync, or sync+restart.</p> <p>Here's a brief explanation of these actions:</p> <ul> <li>rebuild: Compose rebuilds the service image based on the build section and recreates the service with the updated image.</li> <li>sync: Compose keeps the existing service container(s) running, but synchronizes source files with container content according to the target attribute.</li> <li>sync+restart: Compose synchronizes source files with container content according to the target attribute, and then restarts the container.</li> </ul> <p>You can also define a list of patterns for paths to be ignored using the ignore attribute. Any updated file that matches a pattern, or belongs to a folder that matches a pattern, won't trigger services to be re-created. To use Compose Watch, you need to add the watch instructions to your compose.yaml file and then run your application with the docker compose watch command.</p> <p></p>"},{"location":"lab1/compose-watch/#getting-started","title":"Getting Started","text":""},{"location":"lab1/compose-watch/#clone-the-repository","title":"Clone the repository","text":"<pre><code>git clone https://github.com/dockersamples/getting-started-todo-app/\ncd getting-started-todo-app\n</code></pre>"},{"location":"lab1/compose-watch/#switch-to-compose-watch-branch","title":"Switch to compose-watch branch","text":"<pre><code>git checkout compose-watch\n</code></pre>"},{"location":"lab1/compose-watch/#bringing-up-the-app","title":"Bringing up the app","text":"<pre><code>docker compose watch\n</code></pre>"},{"location":"lab1/compose-watch/#make-some-changes","title":"Make some changes","text":"<p>Open a new terminal and modify the following package under frontend/package.json from </p> <pre><code>\"optionalDependencies\": {\n    \"fsevents\": \"^2.1.2\"\n</code></pre> <p>to</p> <pre><code>\"optionalDependencies\": {\n    \"fsevents\": \"^2.1.3\"\n</code></pre> <p>You will find that the frontend service gets rebuild automatcially for you</p> <pre><code>[+] Running 6/6\n \u2714 Network getting-started-todo-app_express-mongo     Created                                                          0.1s \n \u2714 Network getting-started-todo-app_react-express     Created                                                          0.0s \n \u2714 Container mongo                                    Started                                                          1.1s \n \u2714 Container getting-started-todo-app-mongoexpress-1  Started                                                          1.1s \n \u2714 Container backend                                  Started                                                          1.3s \n \u2714 Container frontend                                 Started                                                          1.8s \nWatch enabled\nRebuilding service \"frontend\" after changes were detected...\n[+] Building 52.5s (12/12) FINISHED                                                             docker-container:my-builder\n =&gt; [frontend internal] load build definition from Dockerfile                                                          0.0s\n =&gt; =&gt; transferring dockerfile: 532B                                                                                   0.0s\n =&gt; [frontend internal] load metadata for docker.io/library/node:lts-buster                                            1.1s\n =&gt; [frontend internal] load .dockerignore                                                                             0.0s\n =&gt; =&gt; transferring context: 67B                                                                                       0.0s\n =&gt; [frontend 1/6] FROM docker.io/library/node:lts-buster@sha256:479103df06b40b90f189461b6f824a62906683e26a32c77d7c3e  0.0s\n =&gt; =&gt; resolve docker.io/library/node:lts-buster@sha256:479103df06b40b90f189461b6f824a62906683e26a32c77d7c3e2d855a0e3  0.0s\n =&gt; [frontend internal] load build context                                                                             0.0s\n =&gt; =&gt; transferring context: 1.94kB                                                                                    0.0s\n =&gt; CACHED [frontend 2/6] WORKDIR /usr/src/app                                                                         0.0s\n =&gt; [frontend 3/6] COPY package.json /usr/src/app                                                                      0.0s\n =&gt; [frontend 4/6] COPY package-lock.json /usr/src/app                                                                 0.0s\n =&gt; [frontend 5/6] RUN npm ci                                                                                         24.4s\n =&gt; [frontend 6/6] COPY . /usr/src/app                                                                                 0.3s \n =&gt; [frontend] exporting to docker image format                                                                       26.5s \n =&gt; =&gt; exporting layers                                                                                                8.4s \n =&gt; =&gt; exporting manifest sha256:c3639997f048e5adea7487bafdafaf4ea3f946e071fd273aefb262b72f2c87a8                      0.0s \n =&gt; =&gt; exporting config sha256:1eb3a22fdb9d89316c9bdb1eb1d9f138e0f9545e95af4d812c9db8499309b491                        0.0s\n =&gt; =&gt; sending tarball                                                                                                18.1s\n =&gt; [frontend] importing to docker                                                                                    10.0s\n =&gt; =&gt; loading layer 7544a5e696a4 567B / 567B                                                                         10.0s\n =&gt; =&gt; loading layer 6e1b4449163b 32.77kB / 128.96kB                                                                   9.9s\n =&gt; =&gt; loading layer 874fffdf421f 115.87MB / 121.34MB                                                                  9.9s\n =&gt; =&gt; loading layer b8d4de9612f2 27.14kB / 27.14kB                                                                    0.0s\nservice \"frontend\" successfully built\n</code></pre>"},{"location":"lab1/docker-init/","title":"Docker init","text":"<p>Introduced for the first time in Docker Desktop 4.18, the new docker init CLI generates Docker assets for projects, making it easier to create Docker images and containers. When you run the docker init command in your project directory, it will guide you through the creation of the necessary files for your project with sensible defaults. These files include:</p> <pre><code>.dockerignore\nDockerfile\ndocker-compose.yaml\n</code></pre> <p>The docker init command also allows you to choose the application platform that your project uses and the relative directory of your main package. </p>"},{"location":"lab1/docker-init/#whos-this-for","title":"Who\u2019s this for?","text":"<p>This feature is targeted at developers who want to quickly create and manage Docker assets without having to manually configure everything. </p>"},{"location":"lab1/docker-init/#benefits-of-docker-init","title":"Benefits of Docker Init","text":"<p>The advantages of using the docker init command include:</p> <ul> <li>Simplified Docker asset creation: The command streamlines the creation of necessary Docker files, reducing the chances of errors and ensuring that best practices are followed.</li> <li>Saves time and effort: With the default settings and guided prompts, users can quickly create Docker assets without the need for extensive knowledge of Docker or its syntax.</li> <li>Better project organization: The generated files provide a standardized and organized structure for the project, making it easier for developers to maintain and update the project over time.</li> <li>Enhanced portability: By using Docker assets, projects become more portable across different environments, making it easier to move the project from development to production.</li> </ul> <p></p>"},{"location":"lab1/docker-init/#getting-started","title":"Getting Started","text":"<ul> <li>Install the latest version of Docker Desktop</li> <li>Install Nodejs on your local system</li> </ul> <p>Note: You must download and install the Node pre-built installer on your local system to get the <code>npm install</code> command to work seamlessly. Click here to download</p>"},{"location":"lab1/docker-init/#clone-the-repository","title":"Clone the repository","text":"<pre><code>git clone https://github.com/dockersamples/docker-init-demos\ncd docker-init-demos/node\n</code></pre> <p>The usual way to bring up this node application is to follow the steps:</p> <pre><code>npm install\nnode app.js\n</code></pre> <p>You can verify the output by accessing the URL:</p> <pre><code>curl localhost:8080\n</code></pre> <p>Now let's see how to containerise this project using the <code>docker init</code> CLI.</p>"},{"location":"lab1/docker-init/#run-the-following-command","title":"Run the following command:","text":"<pre><code> docker init\n</code></pre> <p>This utility will walk you through creating the following files with sensible defaults for your project:</p> <ul> <li>Select Node as your application platform</li> <li>Type \"22.2.0\" as Node version, if it doesn't provide you any default option</li> <li>Select npm as package manager</li> <li>Select \"node app.js\" as the command</li> <li>Type \"8080\" as a port that server listens on</li> </ul> <p>The tool creates the following Docker assets for you:</p> <pre><code>  - .dockerignore\n  - Dockerfile\n  - docker-compose.yaml\n</code></pre>"},{"location":"lab1/docker-init/#running-the-container-service","title":"Running the container service","text":"<p><code>docker compose up -d --build</code></p>"},{"location":"lab1/docker-init/#accessing-the-node-app","title":"Accessing the Node app","text":"<pre><code> curl localhost:8080      .\n/\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\\___/ ===\n{                       /  ===-\n\\______ O           __/\n \\    \\         __/\n  \\____\\_______/\n\n\nHello from Docker\n</code></pre>"},{"location":"lab1/docker-workflow/","title":"Docker workflow","text":"<ul> <li> <p>Build: Typically a developer run <code>docker build</code> command to build an image from a Dockerfile, which is a text document that contains instructions for how to build the image.</p> </li> <li> <p>Share: Once a developer builds a Docker image, they can share it with others by pushing it to a container registry. You can use the <code>docker push</code> command to do this.</p> </li> <li> <p>Run: The <code>docker run</code> command lets you create and start a running container based on a Docker image.</p> </li> </ul> <p></p>"},{"location":"lab1/docker-workflow/#docker-inner-loop-development-workflow","title":"Docker Inner-Loop Development workflow","text":"<ul> <li>Development Environment: As you deep-dive into the inner-loop development workflow, developers have their own choice anduse any operating system (OS) they prefer, like Windows, Mac, or Linux. They can also leverage their favorite Integrated Development Environments (IDEs) for coding. This flexibility empowers developers to work in a familiar and comfortable setting.</li> </ul> <ul> <li> <p>Building and storing the application - Once the code is written, the developer uses GitHub Actions. GitHub Actions is a built-in automation tool in GitHub that allows you to automate tasks within your development workflow. In this context, the developer uses GitHub Actions to trigger the building of a Docker image. A Dockerfile, which is a set of instructions that specifies how to build the image, is used in this process.  After the image is built, it's uploaded to a container registry. A container registry acts as a library or repository that stores Docker images.</p> </li> <li> <p>Deployment - Finally, the image is deployed to the cloud. This means the image is uploaded to a cloud platform where it can be run on virtual machines. There are several cloud platforms available, including Google Cloud Platform, Amazon Web Services, and Microsoft Azure. The specific steps for deployment will vary depending on the chosen cloud platform. But generally, it involves using the cloud platform tools to run the Docker image and create a container instance. This container instance then executes the application.</p> </li> </ul>"},{"location":"lab1/overview/","title":"Overview","text":"<p>The inner loop is the iterative process of writing, building, and debugging code that a single developer performs before sharing the code, either publicly or with their team. It is typically characterized by frequent changes to the code as the developer learns more about the problem they are trying to solve.</p> <p>The outer loop is everything else that happens leading up to release. This includes code merge, automated code review, test execution, deployment, controlled (canary) release, and observation of results. It is typically characterized by less frequent changes to the code, as the focus is on ensuring that the code is stable and ready for production..</p> <p>The inner loop is often associated with the development phase of the SDLC, while the outer loop is associated with the testing, deployment, and release phases. However, the two loops are not mutually exclusive, and they can overlap in some cases.</p> <p></p>"},{"location":"lab1/postgres/","title":"Postgres","text":""},{"location":"lab1/postgres/#running-multiple-postgres-containers","title":"Running Multiple Postgres Containers","text":"<pre><code>docker run -d --name postgres1 -e POSTGRES_PASSWORD=dev -p 5432:5432 postgres:latest\n</code></pre> <pre><code>docker run -d --name postgres2 -e POSTGRES_PASSWORD=dev -p 5433:5432 postgres:13\n</code></pre> <pre><code>docker run -d --name postgres3 -e POSTGRES_PASSWORD=dev -p 5434:5432 postgres:12\n</code></pre> <p>Open Docker Dashboard and run the following commands:</p> <pre><code># psql -d postgres -U postgres -W\nPassword: \npsql (17.2 (Debian 17.2-1.pgdg120+1))\nType \"help\" for help.\n\npostgres=# \n</code></pre> <p>The above command includes three flags:</p> <ul> <li>-d - specifies the name of the database to connect to</li> <li>-U - specifies the name of the user to connect as</li> <li>-W - forces psql to ask for the user password before connecting to the database</li> </ul>"},{"location":"lab1/postgres/#listing-all-the-databases-l","title":"Listing all the databases - \\l","text":"<pre><code>\n                                                    List of databases\n   Name    |  Owner   | Encoding | Locale Provider |  Collate   |   Ctype    | Locale | ICU Rules |   Access privileges   \n-----------+----------+----------+-----------------+------------+------------+--------+-----------+-----------------------\n postgres  | postgres | UTF8     | libc            | en_US.utf8 | en_US.utf8 |        |           | \n template0 | postgres | UTF8     | libc            | en_US.utf8 | en_US.utf8 |        |           | =c/po\nstgres          +\n           |          |          |                 |            |            |        |           | postg\nres=CTc/postgres\n template1 | postgres | UTF8     | libc            | en_US.utf8 | en_US.utf8 |        |           | =c/po\nstgres          +\n           |          |          |                 |            |            |        |           | postg\nres=CTc/postgres\n(3 rows)\n</code></pre>"},{"location":"lab1/postgres/#list-all-schemas","title":"List all schemas","text":"<p>The <code>\\dn</code> psql command lists all the database schemas.</p> <pre><code>postgres=# \\dn\n      List of schemas\n  Name  |       Owner       \n--------+-------------------\n public | pg_database_owner\n(1 row)\n\npostgres=#\n</code></pre>"},{"location":"lab1/postgres/#run-the-following-command-to-show-the-database-activity","title":"Run the following command to show the database activity:","text":"<pre><code>SELECT * from pg_stat_activity;  &lt;--- DONT FORGET \";\"\n</code></pre>"},{"location":"lab1/postgres/#result","title":"Result:","text":"<pre><code>datid | datname  | pid | leader_pid | usesysid | usename  | application_name | client_addr | client_host\nname | client_port |         backend_start         |          xact_start           |          query_start\n          |         state_change          | wait_event_type |     wait_event      | state  | backend_xid \n| backend_xmin | query_id |              query              |         backend_type         \n-------+----------+-----+------------+----------+----------+------------------+-------------+------------\n-----+-------------+-------------------------------+-------------------------------+---------------------\n----------+-------------------------------+-----------------+---------------------+--------+-------------\n+--------------+----------+---------------------------------+------------------------------\n     5 | postgres |  85 |            |       10 | postgres | psql             |             |            \n     |          -1 | 2025-01-08 11:40:22.778949+00 |                               | 2025-01-08 11:40:56.\n590114+00 | 2025-01-08 11:41:26.598462+00 | Client          | ClientRead          | idle   |             \n|              |          | SELECT pg_sleep(30);            | client backend\n     5 | postgres |  92 |            |       10 | postgres | psql             |             |            \n     |          -1 | 2025-01-08 11:41:14.359414+00 | 2025-01-08 11:43:52.615603+00 | 2025-01-08 11:43:52.\n615603+00 | 2025-01-08 11:43:52.61561+00  |                 |                     | active |             \n|          750 |          | SELECT * FROM pg_stat_activity; | client backend\n       |          |  64 |            |          |          |                  |             |            \n     |             | 2025-01-08 11:38:28.74611+00  |                               |                     \n          |                               | Activity        | AutovacuumMain      |        |             \n|              |          |                                 | autovacuum launcher\n       |          |  65 |            |       10 | postgres |                  |             |            \n:\n</code></pre>"},{"location":"lab1/postgres/#method-2-using-ask-gordon","title":"Method 2: Using \"Ask Gordon\"","text":"<pre><code>Run a multiple version of postgres with the standard port and POSTGRES_PASSWORD set to dev\n</code></pre>"},{"location":"lab1/postgres/#remove-the-container","title":"Remove the container","text":"<p>Open Docker Dashboard &gt; Selecting all the running Postgres containsrs and delete them in a single step.</p>"},{"location":"lab1/what-is-a-container/","title":"What is a container","text":"<p>Let\u2019s compare containers to smartphone apps. </p> <p></p> <p>Most of us have smartphones that have lots of apps installed on them.</p> <p>When is the last time you thought about how to install the dependencies for one of those apps, how to configure it, and how to set it up? Well, probably never.</p> <p>We typically just open the app store, click the Install button , and then the app is there. <p>And when we open the newly installed red app, we don\u2019t have to worry about how the dependencies and libraries for the green app are going to affect it - they all run in isolated or sandboxed environments.</p> <p>Containers bring this same idea to other types of applications and services, although they are implemented a little differently.</p>"},{"location":"lab2/aws-s3-setup/","title":"Configuring AWS with IAM and S3","text":""},{"location":"lab2/aws-s3-setup/#1-login-to-aws-and-create-a-user","title":"1. Login to AWS and create a user","text":""},{"location":"lab2/aws-s3-setup/#2-add-a-user-called-developer","title":"2. Add a user called developer","text":""},{"location":"lab2/aws-s3-setup/#3-creat-a-group","title":"3. Creat a group","text":""},{"location":"lab2/aws-s3-setup/#4-add-developer-to-admin1-group","title":"4. Add developer to admin1 group","text":""},{"location":"lab2/aws-s3-setup/#5-review-and-save","title":"5. Review and save","text":""},{"location":"lab2/aws-s3-setup/#6-enable-access-keys-and-security-key-for-this-user","title":"6. Enable Access Keys and Security key for this user","text":""},{"location":"lab2/aws-s3-setup/#7-create-a-s3-bucket","title":"7. Create a S3 bucket","text":""},{"location":"lab2/aws-s3-setup/#8-grant-this-user-with-s3-bucket-access","title":"8. Grant this user with S3 bucket access","text":""},{"location":"lab2/getting-started/","title":"Getting started","text":""},{"location":"lab2/getting-started/#a-basic-todo-list-app","title":"A Basic Todo List App","text":"<p>This is a starting point for todo-list app powered with React, Node, Mongo and Mongo Express.</p>"},{"location":"lab2/getting-started/#tech-stack","title":"Tech Stack","text":"<ul> <li>Frontend: React</li> <li>Backend: Node.js</li> <li>Database: Mongo DB</li> <li>Database Admin Interface: MongoExpress</li> </ul>"},{"location":"lab2/getting-started/#clone-the-repository","title":"Clone the repository","text":"<pre><code>git clone https://github.com/dockersamples/getting-started-todo-app\ncd getting-started-todo-app\n</code></pre>"},{"location":"lab2/getting-started/#switch-to-basic-branch","title":"Switch to <code>basic</code> branch","text":"<pre><code>git checkout basic\n</code></pre>"},{"location":"lab2/getting-started/#bringing-up-the-service-containers","title":"Bringing up the service containers","text":"<pre><code>docker compose up -d\n</code></pre> <p>After the application starts, navigate to <code>http://localhost:3000</code> in your web browser.</p>"},{"location":"lab2/getting-started/#logging-into-mongo-express","title":"Logging into Mongo Express","text":"<p>Enter <code>admin/pass</code> as credential to login into Mongo Express and view the database and collections/items.</p>"},{"location":"lab2/overview/","title":"Overview","text":"<p>Container-first development takes the concept of containerization a step further. It involves using containers for every aspect of software development, including the application runtime itself. This means developers can ditch traditional local installations and leverage containers for everything needed to run the application.</p>"},{"location":"lab2/overview/#what-it-means","title":"What it means?","text":"<p>In container-first development, developers work within a containerized environment. They:</p> <ul> <li>Clone the project repository.</li> <li>Run a command (often docker-compose up or docker-compose watch) to start the development environment. This command usually pulls pre-built container images containing the application runtime (e.g., Node.js, Python interpreter) and any dependencies.</li> </ul> <p>That's it! The development environment is up and running entirely within containers. No need to install the application runtime or specific libraries on the developer's machine.</p>"},{"location":"lab2/overview/#benefits-for-developers","title":"Benefits for Developers:","text":"<ul> <li>Extreme Portability: Developers only need a container engine and an IDE to work on the project. This ensures identical development environments regardless of the underlying operating system or pre-installed software.</li> <li>Faster Setup: No time wasted installing the application runtime or fiddling with local configurations. Developers can start coding as soon as the containerized environment is up.</li> <li>Improved Isolation: Each project runs within its own isolated container, preventing conflicts between projects or dependencies from interfering with other applications on the developer's machine.</li> <li>Simplified Collaboration: Team members can easily share and reproduce development environments using the same container images.</li> </ul>"},{"location":"lab2/overview/#choosing-container-first","title":"Choosing Container-First:","text":"<ul> <li>Container-first development is ideal for teams seeking:</li> <li>Maximum portability across development environments.</li> <li>Fast and streamlined development setup.</li> <li>Strong isolation between projects to avoid conflicts.</li> </ul> <p>However, it requires a steeper learning curve for containerization technologies and might have higher resource demands.</p> <p>Container-first development offers a powerful approach for building applications entirely within containerized environments. It streamlines development workflows, ensures consistent development environments, and promotes collaboration. But, it's important to weigh the benefits against the increased complexity and potential resource usage before adopting this approach for your development team.</p>"},{"location":"lab2/services/","title":"Services","text":""},{"location":"lab2/services/#1-clone-the-repository","title":"1. Clone the repository:","text":"<pre><code>git clone https://github.com/dockersamples/getting-started-todo-app\ncd getting-started-todo-app\n</code></pre>"},{"location":"lab2/services/#2-switch-to-container-first-branch","title":"2. Switch to container-first branch","text":"<pre><code>git checkout container-first-aws-mongo\n</code></pre>"},{"location":"lab2/services/#3-add-the-environment-variables","title":"3. Add the Environment Variables","text":"<p>Copy .env.sample to .env file and Ensure that you have the right environmental variable added as shown:</p> <pre><code>MONGODB_URI=mongodb://mongodb:27017/todo-app\nJWT_SECRET=603b31XXXXXXX90d3b8cb62f0a585fd70a5ee0b4d\nAWS_ACCESS_KEY_ID=AKIAXXXXXDDDX\nAWS_SECRET_ACCESS_KEY=hSYXtvXXXXXXXO/k39FGt3u078pYWsh\nAWS_REGION=us-east-1\nS3_BUCKET_NAME=localbuckett\n</code></pre> <p>You can leverage this link to generate JWT token.</p>"},{"location":"lab2/services/#4-bring-up-the-services","title":"4. Bring up the services:","text":"<pre><code>docker compose watch\n</code></pre>"},{"location":"lab2/services/#5-access-the-app","title":"5. Access the app","text":"<p>Open http://localhost:3000 to access the todo-list app. Try adding a task and uploading the image.</p>"},{"location":"lab2/services/#verify-mongo","title":"Verify Mongo","text":"<p>You can verify if task gets added by selecting the container and clicking on \"Exec\" option on the Docker dashboard. Now you should be able to run the following command to verify the tasks.</p> <pre><code># mongosh\nCurrent Mongosh Log ID: 66879e864955d6e7b2f3f54d\nConnecting to:          mongodb://127.0.0.1:27017/?directConnection=true&amp;serverSelectionTimeoutMS=2000&amp;appName=mongosh+2.2.10\nUsing MongoDB:          7.0.12\nUsing Mongosh:          2.2.10\n\nFor mongosh info see: https://docs.mongodb.com/mongodb-shell/\n\n\nTo help improve our products, anonymous usage data is collected and sent to MongoDB periodically (https://www.mongodb.com/legal/privacy-policy).\nYou can opt-out by running the disableTelemetry() command.\n\n------\n   The server generated these startup warnings when booting\n   2024-07-05T07:18:03.008+00:00: Using the XFS filesystem is strongly recommended with the WiredTiger storage engine. See http://dochub.mongodb.org/core/prodnotes-filesystem\n   2024-07-05T07:18:03.737+00:00: Access control is not enabled for the database. Read and write access to data and configuration is unrestricted\n   2024-07-05T07:18:03.738+00:00: /sys/kernel/mm/transparent_hugepage/enabled is 'always'. We suggest setting it to 'never' in this binary version\n   2024-07-05T07:18:03.738+00:00: vm.max_map_count is too low\n------\n\ntest&gt; show dbs\nadmin     40.00 KiB\nconfig    12.00 KiB\nlocal     40.00 KiB\ntodo-app  68.00 KiB\ntest&gt; use todo-app\nswitched to db todo-app\ntodo-app&gt; show collections\ntodos\nusers\ntodo-app&gt; db.todos.showDocuments()\nTypeError: db.todos.showDocuments is not a function\ntodo-app&gt; db.todos.countDocuments()\n1\ntodo-app&gt; db.todos.countDocuments()\n2\ntodo-app&gt; db.todos.countDocuments()\n3\ntodo-app&gt;\n</code></pre>"},{"location":"lab2/services/#verify-the-images-added-to-aws-s3","title":"Verify the images added to AWS S3","text":"<p>Open AWS Dashboard &gt; S3 service to see the list of images uploaded.</p> <p></p>"},{"location":"lab2/tech-stack/","title":"Tech stack","text":"<ul> <li>Frontend: React, Material UI.</li> <li>Backend: Node.js, Express</li> <li>Database: Mongo(Atlas or running locally for storing tasks)</li> <li>Object Storage: AWS S3(for storing images)</li> </ul>"},{"location":"lab3/overview/","title":"Overview","text":"<p>Container-supported development is the idea of using containers to support and enhance development without touching the main application runtime itself. </p>"},{"location":"lab3/overview/#what-it-means","title":"What it means?","text":"<p>The developer will run their application using a runtime installed natively on their machine (such as a JVM, Node engine, or Python interpreter). But, the external dependencies will run in containers. </p>"},{"location":"lab3/overview/#what-benefits-does-it-provide-to-the-developers","title":"What benefits does it provide to the developers?","text":"<p>Even though the developers didn\u2019t go \u201call-in\u201d, Docker still provided significant value by running dependent services out of containers, making it quick and easy to get started and ensure version consistency across the entire team.</p> <p>With Docker, teams can do things that might otherwise have been impossible. They can run local instances of cloud services, run real services in their tests, and more. There is no \u201cone right path\u201d for teams to leverage Docker. You see teams using wrapper scripts that run docker run commands, others using IDE plugins to launch declarative Compose stacks, or programmatic interactions using Testcontainers.In many of these cases, teams can leverage off-the-shelf (or very slightly customized versions of) images from our DOI/DVP catalog.</p>"},{"location":"lab3/overview/#choosing-the-container-supported-approach","title":"Choosing the container-supported approach:","text":"<ul> <li> <p>Separation of Concerns: Developers focus on the core application logic using their familiar runtime (JVM, Node, Python etc.), while external dependencies are isolated in containers.</p> </li> <li> <p>Improved Efficiency:</p> </li> <li> <p>Easier setup: Containers simplify dependency management, reducing time spent configuring environments. Version consistency: All developers use the same container image, ensuring consistent dependencies across the team.</p> </li> <li> <p>Enhanced Capabilities: Docker allows running local simulations of cloud services and real services within tests, providing a more realistic development environment.</p> </li> <li> <p>Flexibility in Implementation: There's no single approach. Teams can use:</p> </li> <li> <p>Wrapper scripts for simple container execution.</p> </li> <li>IDE plugins for launching development environments defined in Docker Compose files.</li> <li> <p>Programming interactions with libraries like Testcontainers.</p> </li> <li> <p>Leveraging Shared Resources: Teams can benefit from pre-built container images from public repositories like Docker Official Images (DOI) and Docker Verified Publishers (DVP).</p> </li> </ul> <p>Overall, container-supported development offers a way to streamline the development process by managing dependencies and enhancing development environments without completely switching to a containerized application runtime.</p>"},{"location":"lab3/services/","title":"How to build and test AWS Cloud applications with LocalStack and Docker","text":"<p>This repo contains the sample application for Building and testing Cloud applications with LocalStack and Docker guide on Docker Docs. This simple to-do List application allows developers to upload images to S3-emulated LocalStack.</p> <p>Notice: This sample repo is intended to support the guide mentioned above. As such, the application code is purposely kept simple to keep the focus on the guide's content and should not be considered production ready.</p>"},{"location":"lab3/services/#tech-stack","title":"Tech Stack","text":"<ul> <li>Frontend: React, Material UI.</li> <li>Backend: Node.js, Express</li> <li>Database: Mongo(running locally for storing tasks)</li> <li>Object Storage: LocalStack (for emulating S3 and storing images locally for testing purposes)</li> </ul>"},{"location":"lab3/services/#project-structure","title":"Project Structure","text":"<p>This project contains the following components:</p> <ul> <li>/backend - This directory contains the Node.js application that handles the server-side logic and interacts with the database. This directory contains configuration settings for uploading images to LocalStack (emulated AWS S3). The uploadConfig.js file is responsible for configuring the S3 client to connect to the LocalStack S3 endpoint. This allows the backend application to store and retrieve images associated with the Todo List items.</li> <li>/frontend - The frontend directory contains the React application that handles the user interface and interacts with the backend. </li> </ul>"},{"location":"lab3/services/#development","title":"Development","text":"<ol> <li>Install awscli-local tool</li> </ol> <pre><code>pip install awscli-local\n</code></pre> <p>In case, it throws error related to python. Follow the below steps:</p> <pre><code>python3 -m venv venv\nsource venv/bin/activate\npip install awscli-local\n</code></pre> <ol> <li>Clone the repository</li> </ol> <pre><code>git clone https://github.com/dockersamples/todo-list-localstack-docker\n</code></pre> <ol> <li>Navigate into the project.</li> </ol> <pre><code>cd todo-list-localstack-docker\n</code></pre>"},{"location":"lab3/services/#run-the-app-natively","title":"Run the app natively","text":""},{"location":"lab3/services/#bring-up-localstack","title":"Bring up LocalStack","text":"<p>To run the app natively, you will need to run LocalStack and Mongo using Docker Compose while running frontend and backend locally.</p> <pre><code>docker compose -f compose-native.yml up -d --build\n</code></pre> <p></p>"},{"location":"lab3/services/#verify-if-localstack-is-up-and-running","title":"Verify if LocalStack is up and running","text":""},{"location":"lab3/services/#add-a-sample-s3-bucket","title":"Add a Sample S3 Bucket","text":"<p>By using the AWS CLI with LocalStack, you can interact with the emulated services exactly as you would with real AWS services. This helps ensure that your application behaves the same way in a local environment as it would in a production environment on AWS.</p> <p>Let\u2019s create a new S3 bucket within the LocalStack environment:</p> <pre><code>awslocal s3 mb s3://mysamplebucket\n</code></pre> <p>The command <code>s3 mb s3://mysamplebucket</code> tells the AWS CLI to create a new S3 bucket (mb stands for \"make bucket\"). The bucket is named <code>mysamplebucket</code> It should show the following result:</p> <pre><code>make_bucket: mysamplebucket\n</code></pre>"},{"location":"lab3/services/#connecting-to-localstack-from-a-non-containerised-node-app","title":"Connecting to LocalStack from a non-containerised Node app","text":"<p>Now it\u2019s time to connect your app to LocalStack. The index.js file, located in the backend/ directory, serves as the main entry point for the backend application.</p> <p>The code interacts with LocalStack\u2019s S3 service, which is accessed via the endpoint defined by the <code>S3_ENDPOINT_URL</code> environment variable, typically set to <code>http://localhost:4556</code> for local development.  </p> <p>The <code>S3Client</code> from the AWS SDK is configured to use this LocalStack endpoint, along with test credentials (<code>AWS_ACCESS_KEY_ID</code> and <code>AWS_SECRET_ACCESS_KEY</code>) that are also sourced from environment variables. This setup allows the application to perform operations on the locally simulated S3 service as if it were interacting with the real AWS S3, making the code flexible for different environments.</p> <p>The code uses multer and multer-s3 to handle file uploads. When a user uploads an image through the <code>/upload</code> route, the file is stored directly in the S3 bucket simulated by LocalStack. The bucket name is retrieved from the environment variable <code>S3_BUCKET_NAME</code>. Each uploaded file is given a unique name by appending the current timestamp to the original file name. The route then returns the URL of the uploaded file within the local S3 service, making it accessible just as it would be if hosted on a real AWS S3 bucket</p>"},{"location":"lab3/services/#bring-up-backend","title":"Bring up Backend","text":"<pre><code>cd backend/\nnpm install\n\n</code></pre> <p>Please note that these are placeholders that LocalStack uses to simulate AWS credentials and not the real values. Hence, no changes are needed.</p> <pre><code>AWS_ACCESS_KEY_ID=test\nAWS_SECRET_ACCESS_KEY=test\nS3_BUCKET_NAME=mysamplebucket\nS3_ENDPOINT_URL=http://localhost:4566\nMONGODB_URI=mongodb://mongodb:27017/todos\nAWS_REGION=us-east-1\n</code></pre> <p>Start the backend server:</p> <pre><code>node index.js\n</code></pre> <p>You will see the message that the backend service has successfully started at port 5000.</p>"},{"location":"lab3/services/#start-the-frontend","title":"Start the frontend","text":"<p>Open a new terminal and run the following command:</p> <pre><code>cd frontend/\nnpm run dev\n</code></pre> <p>By now, you should see the following message</p> <pre><code>VITE v5.4.2  ready in 110 ms\n\n  \u279c  Local:   http://localhost:5173/\n  \u279c  Network: use --host to expose\n  \u279c  press h + enter to show help\n\n</code></pre>"},{"location":"lab3/services/#try-adding-a-task-and-uploading-the-image","title":"Try adding a task and uploading the image","text":"<p>It shows the image is successfully uploaded.</p>"},{"location":"lab3/services/#check-the-localstack-container-logs","title":"Check the LocalStack container logs","text":""},{"location":"lab3/services/#check-the-mongo-container-logs","title":"Check the Mongo container logs","text":"<pre><code># mongosh\nCurrent Mongosh Log ID: 66cb1093118d7d4cc1c76a8a\nConnecting to:          mongodb://127.0.0.1:27017/?directConnection=true&amp;serverSelectionTimeoutMS=2000&amp;appName=mongosh+2.3.0\nUsing MongoDB:          7.0.12\nUsing Mongosh:          2.3.0\n\nFor mongosh info see: https://www.mongodb.com/docs/mongodb-shell/\n\n\nTo help improve our products, anonymous usage data is collected and sent to MongoDB periodically (https://www.mongodb.com/legal/privacy-policy).\nYou can opt-out by running the disableTelemetry() command.\n\n------\n   The server generated these startup warnings when booting\n   2024-08-25T10:58:46.918+00:00: Using the XFS filesystem is strongly recommended with the WiredTiger storage engine. See http://dochub.mongodb.org/core/prodnotes-filesystem\n   2024-08-25T10:58:47.668+00:00: Access control is not enabled for the database. Read and write access to data and configuration is unrestricted\n   2024-08-25T10:58:47.668+00:00: /sys/kernel/mm/transparent_hugepage/enabled is 'always'. We suggest setting it to 'never' in this binary version\n   2024-08-25T10:58:47.668+00:00: vm.max_map_count is too low\n------\n\ntest&gt; show dbs\nadmin   40.00 KiB\nconfig  60.00 KiB\nlocal   40.00 KiB\ntodos    8.00 KiB\ntest&gt; use todos\nswitched to db todos\ntodos&gt; db.todos.countDocuments()\n2\ntodos&gt; db.todos.countDocuments()\n3\ntodos&gt; \n</code></pre>"},{"location":"lab3/services/#stop-the-container-services","title":"Stop the container services","text":"<pre><code>docker compose -f compose-native.yml down\n</code></pre>"},{"location":"lab3/services/#connecting-to-containerised-localstack-from-a-containerised-node-app","title":"Connecting to containerised LocalStack from a containerised Node app","text":"<pre><code>docker compose -f compose.yml up -d --build\n</code></pre>"},{"location":"lab3/services/#add-a-sample-s3-bucket_1","title":"Add a Sample S3 Bucket","text":"<p>Using the AWS CLI with LocalStack lets you interact with the emulated services exactly as you would with real AWS services. This helps ensure that your application behaves the same way in a local environment as it would in a production environment on AWS.</p> <p>Let\u2019s create a new S3 bucket within the LocalStack environment:</p> <pre><code>awslocal s3 mb s3://mysamplebucket\n</code></pre> <p>The command <code>s3 mb s3://mysamplebucket</code> tells the AWS CLI to create a new S3 bucket (mb stands for \"make bucket\"). The bucket is named <code>mysamplebucket</code> It should show the following result:</p> <pre><code>make_bucket: mysamplebucket\n</code></pre>"},{"location":"lab3/services/#try-adding-a-task-and-uploading-the-image_1","title":"Try adding a task and uploading the image","text":"<p>It shows the image is successfully uploaded.</p>"},{"location":"lab3/services/#check-the-localstack-container-logs_1","title":"Check the LocalStack container logs","text":""},{"location":"lab3/services/#check-the-mongo-container-logs_1","title":"Check the Mongo container logs","text":"<pre><code># mongosh\nCurrent Mongosh Log ID: 66cb1093118d7d4cc1c76a8a\nConnecting to:          mongodb://127.0.0.1:27017/?directConnection=true&amp;serverSelectionTimeoutMS=2000&amp;appName=mongosh+2.3.0\nUsing MongoDB:          7.0.12\nUsing Mongosh:          2.3.0\n\nFor mongosh info see: https://www.mongodb.com/docs/mongodb-shell/\n\n\nTo help improve our products, anonymous usage data is collected and sent to MongoDB periodically (https://www.mongodb.com/legal/privacy-policy).\nYou can opt-out by running the disableTelemetry() command.\n\n------\n   The server generated these startup warnings when booting\n   2024-08-25T10:58:46.918+00:00: Using the XFS filesystem is strongly recommended with the WiredTiger storage engine. See http://dochub.mongodb.org/core/prodnotes-filesystem\n   2024-08-25T10:58:47.668+00:00: Access control is not enabled for the database. Read and write access to data and configuration is unrestricted\n   2024-08-25T10:58:47.668+00:00: /sys/kernel/mm/transparent_hugepage/enabled is 'always'. We suggest setting it to 'never' in this binary version\n   2024-08-25T10:58:47.668+00:00: vm.max_map_count is too low\n------\n\ntest&gt; show dbs\nadmin   40.00 KiB\nconfig  60.00 KiB\nlocal   40.00 KiB\ntodos    8.00 KiB\ntest&gt; use todos\nswitched to db todos\ntodos&gt; db.todos.countDocuments()\n2\ntodos&gt; db.todos.countDocuments()\n3\ntodos&gt; \n</code></pre>"},{"location":"lab3/tech-stack/","title":"Tech stack","text":"<ul> <li>Frontend: React, Material UI.</li> <li>Backend: Node.js, Express</li> <li>Database: Mongo(running locally for storing tasks)</li> <li>Object Storage: Localstack (for emulating S3 and storing images locally for testing purpose)</li> </ul>"},{"location":"lab4/getting-started/","title":"Getting Started","text":""},{"location":"lab4/getting-started/#prereq","title":"Prereq","text":"<ul> <li>Install the latest version of Docker Desktop 4.42+</li> <li>Ensure that \u201cDocker Model Runner\u201d is enabled.</li> </ul> <p>There are two ways to enable Model Runner - either using CLI or using Docker Dashboard.</p>"},{"location":"lab4/getting-started/#using-cli","title":"Using CLI","text":"<pre><code>docker desktop enable model-runner\n</code></pre>"},{"location":"lab4/getting-started/#using-docker-dashboard","title":"Using Docker Dashboard","text":"<p>The \"Enable host-side TCP support\" feature allows Docker Model Runner to  additionally accept connections on the host OS on the specified TCP port (default: 12434) rather than only through the host Docker socket (/var/run/docker.sock). You can change this to another port if needed, particularly if 12434 is already in use by another application. We will see its usage later in the docs.</p> <p>Once you enable the option, select \u201cApply &amp; Restart\u201d.</p> <p>If you\u2019re not seeing the \u201cEnable Model Runner\u201d option, it is recommended to enable \u201cUse nightly builds\u201d option under Software Updates and try to see if the option is available. If still facing issue, reach out to Eva.</p> <p>Open up the terminal and you should be able to see docker model as the new CLI.</p> <pre><code>docker model --help\nUsage:  docker model COMMAND\n\nDocker Model Runner\n\nCommands:\n  inspect     Display detailed information on one model\n  list        List the available models that can be run with the Docker Model Runner\n  pull        Download a model\n  rm          Remove a model downloaded from Docker Hub\n  run         Run a model with the Docker Model Runner\n  status      Check if the Docker Model Runner is running\n  version     Show the Docker Model Runner version\n\nRun 'docker model COMMAND --help' for more information on a command.\n</code></pre>"},{"location":"lab4/getting-started/#check-if-the-model-runner-is-running-or-not","title":"Check if the Model Runner is running or not","text":"<pre><code>docker model status\nDocker Model Runner is running\n</code></pre>"},{"location":"lab4/getting-started/#list-the-available-models","title":"List the available models","text":"<pre><code>docker model ls\nMODEL  PARAMETERS  QUANTIZATION  ARCHITECTURE  FORMAT  MODEL ID  CREATED  SIZE\n</code></pre> <p>The response shows an empty list. Let\u2019s go ahead and download the model from the Docker Hub.</p>"},{"location":"lab4/getting-started/#download-a-model","title":"Download a model","text":"<pre><code>docker model pull ai/llama3.2:1B-Q8_0\n</code></pre> <p>All these models are hosted on https://hub.docker.com/u/ai: </p> <pre><code>ai/gemma3\nai/llama3.2\nai/qwq\nai/mistral-nemo\nai/mistral\nai/phi4\nai/qwen2.5\nai/deepseek-r1-distill-llama (distill means it\u2019s not the actual RL-ed deepseek, it\u2019s a llama trained on DeepSeek-R1 inputs/outputs) \n</code></pre> <p>More models will be coming in the future, we plan to add more popular ones first. </p>"},{"location":"lab4/getting-started/#list-the-model","title":"List the Model","text":"<pre><code>docker model ls\nMODEL                PARAMETERS  QUANTIZATION  ARCHITECTURE  MODEL ID      CREATED       SIZE\nai/llama3.2:1B-Q8_0  1.24 B      Q8_0          llama         a15c3117eeeb  20 hours ago  1.22 GiB\n</code></pre>"},{"location":"lab4/getting-started/#use-docker-model-run-to-send-a-single-message","title":"Use docker model run to send a single message","text":"<pre><code>docker model run ai/llama3.2:1B-Q8_0 \"Hi\"\nHello! How can I help you today?\n</code></pre>"},{"location":"lab4/getting-started/#run-the-model-in-interactive-mode","title":"Run the Model in interactive mode","text":"<pre><code>docker model run ai/llama3.2:1B-Q8_0\nInteractive chat mode started. Type '/bye' to exit.\n&gt; why is water blue?\nWater appears blue because ...\n</code></pre>"},{"location":"lab4/getting-started/#remove-the-model","title":"Remove the model","text":"<pre><code>docker model rm ai/llama3.2:1B-Q8_0\n</code></pre>"},{"location":"lab4/getting-started/#packaging-your-own-ai-model","title":"Packaging your own AI Model","text":""},{"location":"lab4/getting-started/#step-1-pull-the-model-from-hugging-face","title":"Step 1. Pull the model from Hugging Face","text":"<pre><code>docker model pull hf.co/bartowski/Llama-3.2-1B-Instruct-GGUF\nDownloaded: 769.73 MB\nModel pulled successfully\n</code></pre>"},{"location":"lab4/getting-started/#step-2-setup-a-local-docker-registry","title":"Step 2. Setup a local Docker registry","text":"<pre><code>docker run -d -p 5000:5000 --name registry registry:2\n</code></pre>"},{"location":"lab4/getting-started/#step-3-tag-the-model-for-your-local-registry","title":"Step 3. Tag the model for your local registry","text":"<pre><code>docker model tag hf.co/bartowski/Llama-3.2-1B-Instruct-GGUF localhost:5000/foobar\nModel \"hf.co/bartowski/llama-3.2-1b-instruct-gguf\" tagged successfully with \"localhost:5000/foobar:latest\"\n</code></pre>"},{"location":"lab4/getting-started/#step-4-push-the-model-to-your-local-registry","title":"Step 4. Push the model to your local registry","text":"<pre><code>docker model push localhost:5000/foobar\nUploaded: 770.00 MB\nModel pushed successfully\n</code></pre>"},{"location":"lab4/getting-started/#step-5-push-the-model-to-your-local-registry","title":"Step 5. Push the model to your local registry","text":"<pre><code>docker model push localhost:5000/foobar\nUploaded: 770.00 MB\nModel pushed successfully\n</code></pre>"},{"location":"lab4/getting-started/#step-6-list-the-available-models","title":"Step 6. List the available models","text":"<pre><code>docker model ls\nMODEL NAME                                  PARAMETERS  QUANTIZATION  ARCHITECTURE  MODEL ID      CREATED       SIZE\nai/llama3.2:1B-Q8_0                         1.24 B      Q8_0          llama         a15c3117eeeb  2 months ago  1.22 GiB\nhf.co/bartowski/llama-3.2-1b-instruct-gguf  1.24B                     llama         7ca6390d8288  8 months ago  808M\nlocalhost:5000/foobar:latest  \n</code></pre>"},{"location":"lab4/overview/","title":"Overview","text":""},{"location":"lab4/overview/#docker-model-runner","title":"Docker Model Runner","text":"<ul> <li>Docker Model Runner is a new experimental feature introduced in Docker Desktop for Mac 4.40+. </li> <li>It provides a Docker-native experience for running Large Language Models (LLMs) locally, seamlessly integrating with existing container tooling and workflows. </li> <li>The feature is specifically optimized to utilize Apple Silicon Mac's GPU resources for efficient model inference as of now. </li> </ul>"},{"location":"lab4/overview/#what-problem-does-it-solve","title":"What problem does it solve?","text":"<p>With the Model Runner feature, Docker provides inference capabilities to developers on their laptop, and in the future in CI, allowing them to run LLM models locally. This is an important feature to help developing GenAI applications. The runner essentially provides GPU-accelerated inference engines that are accessible both through the Docker socket (<code>/var/run/docker.sock</code>) and via a TCP connection at <code>model-runner.docker.internal:80</code>.</p>"},{"location":"lab4/overview/#new-docker-model-cli","title":"New <code>docker model</code> CLI","text":"<p>Docker Desktop 4.40+ introduces <code>docker model</code> CLI as the first class-citizen. This means AI models are now treated as fundamental, well-supported objects within the Docker CLI, similar to how Docker already treats containers, images, and volumes. </p> <pre><code>docker model --help\nUsage:  docker model COMMAND\n\nDocker Model Runner\n\nCommands:\n  inspect     Display detailed information on one model\n  list        List the available models that can be run with the Docker Model Runner\n  pull        Download a model\n  rm          Remove a model downloaded from Docker Hub\n  run         Run a model with the Docker Model Runner\n  status      Check if the Docker Model Runner is running\n  version     Show the Docker Model Runner version\n\nRun 'docker model COMMAND --help' for more information on a command.\n</code></pre> <p>By using this new CLI, developers can:</p> <ul> <li>Pull models from registries (e,g Docker Hub)</li> <li>Run models locally with GPU acceleration</li> <li>Integrate models into their development workflows</li> <li>Test GenAI applications during development without relying on external APIs</li> </ul> <p>This capability is particularly valuable for developing and testing GenAI applications locally before deployment, allowing for faster iteration cycles and reduced dependency on cloud services during development.</p>"},{"location":"lab4/overview/#architecture-of-docker-model-runner","title":"Architecture of Docker Model Runner","text":"<p>With Docker Model Runner, the AI model DOES NOT run in a container. Instead, Docker Model Runner uses a host-installed inference server (llama.cpp for now) that runs natively on your Mac rather than containerizing the model. We do plan to support additional inference (i.e MLX) in future releases.</p>"},{"location":"lab4/overview/#1-host-level-process","title":"1. Host-level process:","text":"<p>Docker Desktop runs llama.cpp directly on your host machine This allows direct access to the hardware GPU acceleration on Apple Silicon</p>"},{"location":"lab4/overview/#2-gpu-acceleration","title":"2. GPU acceleration:","text":"<p>By running directly on the host, the inference server can access Apple's Metal API This provides direct GPU acceleration without the overhead of containerization You can see the GPU usage in Activity Monitor when queries are being processed</p>"},{"location":"lab4/overview/#3-model-loading-process","title":"3. Model Loading Process:","text":"<p>When you run docker model pull, the model files are downloaded from the Docker Hub These models are cached locally on the host machine's storage  Models are dynamically loaded into memory by llama.cpp when needed</p> <p>Note: Unlike traditional Docker containers that package large AI models with &gt; the model runtime (which results in slow deployment), Model Runner separates &gt; the model from the runtime, allowing for faster deployment. </p> <p>Model Runner enables local LLM execution. It runs large language models  (LLMs) directly on your machine rather than sending data to external API  services. This means your data never leaves your infrastructure. All you need &gt; to do is pull the model from Docker Hub and start integrating it with your  application.</p>"},{"location":"lab4/projects/genai-chatbot/","title":"GenAI Chatbot","text":"<p>A modern, full-stack chat application demonstrating how to integrate React frontend with a Go backend and run local Large Language Models (LLMs) using Docker's Model Runner.</p> <p>This repo also integrates the GenAI app with the Observability stack that includes Prometheus, Grafana and Jaeger.</p>"},{"location":"lab4/projects/genai-chatbot/#overview","title":"Overview","text":"<p>This project showcases a complete Generative AI interface that includes:</p> <ul> <li>React/TypeScript frontend with a responsive chat UI</li> <li>Go backend server for API handling</li> <li>Integration with Docker's Model Runner to run Llama 3.2 locally</li> <li>Comprehensive observability with metrics, logging, and tracing</li> <li>llama.cpp metrics integration directly in the UI</li> </ul>"},{"location":"lab4/projects/genai-chatbot/#architecture","title":"Architecture","text":"<p>The application consists of these main components:</p> <p></p>"},{"location":"lab4/projects/genai-chatbot/#prerequisites","title":"Prerequisites","text":"<p>Before we begin, make sure you have:</p> <ul> <li>Docker Desktop (version 4.40 or newer) </li> <li>Docker Model Runner enabled</li> <li>At least 16GB of RAM for running AI models efficiently</li> <li>Familiarity with Go (for backend development)</li> <li>Familiarity with React and TypeScript (for frontend development)</li> </ul> <pre><code>services:\n  chat:\n    image: my-chat-app\n    depends_on:\n      - ai_runner\n\n  ai_runner:\n    provider:\n      type: model\n      options:\n        model: ai/smollm2\n</code></pre> <p>Notice the dedicated provider attribute in the ai_runner service. This attribute specifies that the service is a model provider and lets you define options such as the name of the model to be used. There is also a depends_on attribute in the chat service. This attribute specifies that the chat service depends on the ai_runner service. This means that the ai_runner service will be started before the chat service to allow injection of model information to the chat service.</p>"},{"location":"lab4/projects/genai-chatbot/#docker-compose-support-for-model-runner","title":"Docker Compose Support for Model Runner","text":"<p>Docker Model Runner can be integrated with Docker Compose to run AI models as part of your multi-container applications. This lets you define and run AI-powered applications alongside your other services.</p> <p>Compose introduces a new service type called provider that allows you to declare platform capabilities required by your application. For AI models, you can use the model type to declare model dependencies. Here's an example of how to define a model provider:</p>"},{"location":"lab4/projects/genai-chatbot/#clone-the-repository","title":"Clone the repository","text":"<pre><code>git clone https://github.com/dockersamples/genai-model-runner-metrics\ncd genai-model-runner-metrics\n</code></pre>"},{"location":"lab4/projects/genai-chatbot/#enable-docker-model-runner-in-docker-desktop","title":"Enable Docker Model Runner in Docker Desktop","text":"<p>Go to Settings &gt; Features in Development &gt; Beta tab Enable \"Docker Model Runner\" Select \u201cApply and restart\u201d</p> <p></p>"},{"location":"lab4/projects/genai-chatbot/#download-the-model","title":"Download the model","text":"<pre><code>docker model pull ai/llama3.2:1B-Q8_0\n</code></pre>"},{"location":"lab4/projects/genai-chatbot/#verify-the-backendenv","title":"Verify the backend.env","text":"<pre><code>BASE_URL=http://localhost:12434/engines/llama.cpp/v1/\nMODEL=ai/llama3.2:1B-Q8_0\nAPI_KEY=${API_KEY:-dockermodelrunner}\n\n# Observability configuration\nLOG_LEVEL=info\nLOG_PRETTY=true\nTRACING_ENABLED=true\nOTLP_ENDPOINT=jaeger:4318\n</code></pre>"},{"location":"lab4/projects/genai-chatbot/#start-the-application-using-docker-compose","title":"Start the application using Docker Compose","text":"<pre><code>docker compose up -d --build\n</code></pre> <p>You can access the frontend at http://localhost:3000</p> <p></p> <p>To access Grafana, use the following address: http://localhost:3001 (admin/admin)</p> <p></p> <p>Ensure that you provide <code>http://prometheus:9090</code> instead of <code>localhost:9090</code> to see the metrics on the Grafana dashboard.</p> <ul> <li>Jaeger UI: http://localhost:16686</li> <li>Prometheus: http://localhost:9091</li> </ul> <p></p>"},{"location":"lab4/projects/genai-chatbot/#how-it-works","title":"How It Works","text":"<ol> <li>The frontend sends chat messages to the backend API</li> <li>The backend formats the messages and sends them to the Model Runner</li> <li>The LLM processes the input and generates a response</li> <li>The backend streams the tokens back to the frontend as they're generated</li> <li>The frontend displays the incoming tokens in real-time</li> <li>Observability components collect metrics, logs, and traces throughout the process</li> </ol>"},{"location":"lab5/getting-started/","title":"Getting Started","text":""},{"location":"lab5/getting-started/#prereq","title":"Prereq","text":"<ul> <li>Ensure that you have Docker Desktop 4.42+ installed on your system.</li> <li>Enable MCP Toolkit in Docker Desktop</li> </ul>"},{"location":"lab5/overview/","title":"Overview","text":"<p>MCP refers to Model Context Protocol. It is an open protocol that standardizes how applications provide context to LLMs. </p> <p>Think of MCP like a USB-C port for AI applications. Just as USB-C provides a standardized way to connect your devices to various peripherals and accessories, MCP provides a standardized way to connect AI models to different data sources and tools.</p>"},{"location":"lab5/overview/#a-typical-mcp-workflow","title":"A Typical MCP Workflow","text":""},{"location":"lab5/overview/#user-interaction","title":"User Interaction","text":"<ul> <li>User submits a prompt (e.g., \"Fetch me list of users in the Slack\")</li> <li>Users interact through various interfaces/applications connected to MCP</li> </ul>"},{"location":"lab5/overview/#mcp-hosts","title":"MCP Hosts","text":"<ul> <li>Acts as central orchestration layer for the collaboration platform</li> <li>Contains MCP Clients with different applications (Claude, Cursor, etc.)</li> <li>Handles user interactions and connects to backend services</li> </ul>"},{"location":"lab5/overview/#client-server-communication-layer","title":"Client-Server Communication Layer","text":"<ul> <li>Initial Request: Client sends user's prompt to appropriate servers</li> <li>Initial Response: Servers provide initial processing results</li> <li>Notification: Ongoing updates as processing continues (enables feedback loops)</li> </ul>"},{"location":"lab5/overview/#tool-selection","title":"Tool Selection","text":"<ul> <li>Determines which tools are appropriate for fulfilling user requests</li> <li>Bridges client and server sides by matching user needs with available capabilities</li> </ul>"},{"location":"lab5/overview/#mcp-servers","title":"MCP Servers","text":"<ul> <li>Backend services that process requests, including:</li> <li>Kubernetes (container orchestration)</li> <li>Slack (communication)</li> <li>GitHub (code and version control)</li> <li>PostgreSQL (database operations)</li> <li>Grafana (monitoring and analytics)</li> </ul>"},{"location":"lab5/overview/#capabilities-branches","title":"Capabilities Branches","text":"<ul> <li>Tools: Specific utilities that servers employ to fulfill requests</li> <li>Resources: Assets and data available to the system</li> <li>Prompts: Template instructions for guiding LLM interactions</li> </ul>"},{"location":"lab5/overview/#data-sources","title":"Data Sources","text":"<ul> <li>Database: Structured data storage</li> <li>Web Server: Internet-accessible resources</li> <li>Local Files: Filesystem resources</li> </ul>"},{"location":"lab5/overview/#additional-components","title":"Additional Components","text":"<ul> <li>Notification: Alert system that ensures prompt delivery of results when operations complete</li> <li>Sampling: Process for selecting representative data from large datasets to balance accuracy with computational efficiency</li> </ul>"},{"location":"lab5/overview/#challenges-with-the-mcp-landscape","title":"Challenges with the MCP Landscape","text":"<p>However, the current MCP experience faces several challenges:</p> <ul> <li>Fragmented Discovery: Developers struggle to find MCP servers across registries, community lists, and blog posts\u2014with no way to verify which are official and trustworthy.</li> <li>Complex Setup: Getting started requires cloning repositories, managing conflicting dependencies, and self-hosting services that often aren't containerized, hindering portability.</li> <li>Security Concerns: Many MCP tools run with full host access (via npx or uvx) without isolation or sandboxing. Credentials are commonly passed as plain text environment variables, exposing sensitive data.</li> <li>Lack of Enterprise Readiness: Current tools often miss critical features like policy enforcement, audit logs, and standardized security practices.</li> </ul>"},{"location":"lab5/overview/#how-docker-solves-these-challenges","title":"How Docker solves these challenges","text":"<p>Docker is addressing these challenges with two complementary offerings:</p>"},{"location":"lab5/overview/#1-docker-mcp-catalog","title":"1. Docker MCP Catalog:","text":"<p>A trusted hub for discovering and accessing verified MCP servers, seamlessly integrated into Docker Hub with over 100 verified tools at launch.</p> <p>URL: https://hub.docker.com/catalogs/mcp </p> <p></p>"},{"location":"lab5/overview/#2-docker-mcp-toolkit","title":"2. Docker MCP Toolkit:","text":"<p>A suite of tools and services that make MCP servers secure, seamless, and instantly usable on your local machine or anywhere Docker runs.</p> <p>URL: https://open.docker.com/extensions/marketplace?extensionId=docker/labs-ai-tools-for-devs</p>"},{"location":"lab5/overview/#docker-as-a-mcp-runtime","title":"Docker as a MCP Runtime","text":"<p>Every time a new MCP server is added, a config file needs to be updated and the MCP client needs to be updated. The current workaround is to develop MCP servers which configure new MCP servers, but even this requires reloading. </p> <p></p> <p>A much better approach is to simply use one MCP server: Docker. This MCP server acts as a gateway into a dynamic set of containerized tools.</p> <p></p>"},{"location":"lab5/projects/Docker-CLI-With-Gordon/","title":"Docker MCP Server and Gordon","text":""},{"location":"lab5/projects/Docker-CLI-With-Gordon/#prerequisites","title":"Prerequisites","text":"<p>Before we start, make sure you have:</p> <ul> <li>Docker Desktop 4.42.0+ with the MCP Toolkit Extension installed</li> <li>Ensure that Docker AI is enabled under Docker Dashboard</li> </ul>"},{"location":"lab5/projects/Docker-CLI-With-Gordon/#step-1-select-docker-cli-under-mcp-server","title":"Step 1. Select Docker CLI under MCP Server","text":""},{"location":"lab5/projects/Docker-CLI-With-Gordon/#step-2-select-gordon-under-mcp-client","title":"Step 2. Select Gordon under MCP Client","text":""},{"location":"lab5/projects/Docker-CLI-With-Gordon/#step-3-ensure-that-docker-cli-is-enabled-under-ask-gordon","title":"Step 3. Ensure that Docker CLI is enabled under Ask Gordon","text":""},{"location":"lab5/projects/Docker-CLI-With-Gordon/#prompt-1","title":"Prompt 1:","text":"<p>\"List out all the containers running on my system\"</p> <p></p>"},{"location":"lab5/projects/Docker-CLI-With-Gordon/#prompt-2","title":"Prompt 2:","text":"<p>\"Create a new redis container with the name 'myredis' and run it on port 6379\"</p> <p></p>"},{"location":"lab5/projects/Docker-CLI-With-VSCode/","title":"Docker MCP Server and VS Code","text":""},{"location":"lab5/projects/Docker-CLI-With-VSCode/#prerequisites","title":"Prerequisites","text":"<p>Before we start, make sure you have:</p> <ul> <li>Docker Desktop 4.41.0+ with the MCP Toolkit Extension installed</li> <li>Node.js (v18 or later) for running the frontend</li> <li>VS Code (or any IDE of your choice)</li> </ul>"},{"location":"lab5/projects/Docker-CLI-With-VSCode/#setting-up-the-sample-database","title":"Setting Up the Sample Database","text":"<p>Instead of using an empty Postgres database, let's use a real example with actual data. We'll use a sample product catalog service:</p>"},{"location":"lab5/projects/Docker-CLI-With-VSCode/#step-1-clone-the-sample-catalog-service","title":"Step 1. Clone the sample catalog service","text":"<pre><code>git clone https://github.com/ajeetraina/catalog-service-node\ncd catalog-service-node\n</code></pre>"},{"location":"lab5/projects/Docker-CLI-With-VSCode/#step-2-start-the-backend-services-includes-postgres-with-sample-data","title":"Step 2. Start the backend services (includes Postgres with sample data)","text":"<pre><code>docker compose up -d --build\n</code></pre> <p>This will spin up:</p> <ul> <li>A Postgres database on port 5432 with sample catalog data</li> <li>A Node.js backend service</li> <li>Sample data including products, categories, and inventory</li> </ul> <p>Now let's bring up the frontend to see what data we're working with:</p>"},{"location":"lab5/projects/Docker-CLI-With-VSCode/#step-3-install-frontend-dependencies","title":"Step 3. Install frontend dependencies","text":"<pre><code>npm install\n</code></pre>"},{"location":"lab5/projects/Docker-CLI-With-VSCode/#step-4-start-the-development-server","title":"Step 4. Start the development server","text":"<pre><code>npm run dev\n</code></pre> <p>Open your browser to `http://localhost:5173 to see the catalog application. This gives you a visual understanding of the data structure we'll be querying with Claude.</p> <p>Hit \"Create Product\" button and start adding the new items to your Product catalog system.</p> <p>Perfect! Now we have a realistic database to work with instead of an empty one.</p>"},{"location":"lab5/projects/Docker-CLI-With-VSCode/#step-5-setting-up-mcp-toolkit","title":"Step 5. Setting up MCP Toolkit","text":"<p>Open Docker Desktop and navigate to the MCP Toolkit section in the sidebar.</p> <p>Enable Docker MCP Server</p> <p></p>"},{"location":"lab5/projects/Docker-CLI-With-VSCode/#step-6-configuring-the-vs-code","title":"Step 6. Configuring the VS Code","text":"<p>Open your VS Code and install the MCP Toolkit extension if you haven't already.</p>"},{"location":"lab5/projects/Docker-CLI-With-VSCode/#step-7-add-mcp-server","title":"Step 7. Add MCP Server","text":""},{"location":"lab5/projects/Docker-CLI-With-VSCode/#step-8-using-github-co-pilot","title":"Step 8. Using GitHub Co-Pilot","text":"<p>It's time to use GitHub Co-Pilot to interact with the Docker CLI MCP server. Select Agent under Co-Pilot and select tools that are available to chat.</p> <p></p>"},{"location":"lab5/projects/Docker-CLI-With-VSCode/#step-8-chatting-with-github-co-pilot","title":"Step 8. Chatting with GitHub Co-Pilot","text":"<p>Prompt: \"list out all the containers running on my Docker Desktop\"</p> <p></p>"},{"location":"lab5/projects/Docker-CLI-With-VSCode/#troubleshooting","title":"Troubleshooting:","text":"<p>In case you face the following issuse:</p> <pre><code>Reason: You may not include more than 128 tools in your request.\n</code></pre> <p>The fix is to reduce the number of tools in your request to 128 or fewer.  You can do this by selecting only the necessary tools you want to use with GitHub Co-Pilot.</p>"},{"location":"lab5/projects/GitHub-MCP-Gordon/","title":"GitHub MCP Server and Gordon","text":"<p>Let\u2019s see how to use GitHub MCP Server using Gordon as well as Claude Desktop in the following steps:</p>"},{"location":"lab5/projects/GitHub-MCP-Gordon/#step-1-create-a-github-personal-access-token-pat","title":"Step 1: Create a GitHub Personal Access Token (PAT)","text":"<ul> <li>Go to GitHub.com and sign in to your account</li> <li>Click your profile picture in the top-right corner</li> <li>Select \"Settings\"</li> <li>Scroll down to \"Developer settings\" in the left sidebar</li> <li>Click on \"Personal access tokens\" \u2192 \"Tokens (classic)\"</li> <li>Click \"Generate new token\" \u2192 \"Generate new token (classic)\"</li> <li>Give your token a descriptive name like \"Docker MCP GitHub Access\"</li> <li>Select the following scopes (permissions):</li> <li>repo (Full control of private repositories)</li> <li>workflow (if you need workflow actions)</li> <li>read:org (if you need organization access)</li> <li>Click \"Generate token\"</li> </ul>"},{"location":"lab5/projects/GitHub-MCP-Gordon/#step-2-configure-the-github-mcp-server-in-docker","title":"Step 2: Configure the GitHub MCP Server in Docker","text":"<ul> <li>Open Docker Desktop</li> <li>Navigate to the MCP Server</li> <li>Find the GitHub tool (official) card and click on it to expand details.</li> </ul> <p>In your terminal, set up the GitHub token as a secret:</p> <pre><code>docker mcp secret set GITHUB.PERSONAL_ACCESS_TOKEN=github_pat_YOUR_TOKEN_HERE\n</code></pre> <p>For example:</p> <pre><code>docker mcp secret set GITHUB.PERSONAL_ACCESS_TOKEN=github_pat_11AACMRCAXXXXXXxEp_QRZW43Wo1k6KYWwDXXXXXXXXGPXLZ7EGEnse82YM\nInfo: No policy specified, using default policy\n</code></pre> <p>If you have enabled Ask Gordon and enabled MCP Catalog (as shown in the following screenshot), then you can use docker ai command to play around with your GitHub repository.</p> <p></p> <p>Run the following docker ai command to create a new repository on your GitHub repo directly.</p> <pre><code>docker ai \"create a repo called modelorbital on my github repo\"\n\n    \u2022 Calling create_repository...\n\nThe repository \"modelorbital\" has been created on your GitHub account. You can access it here: https://github.com/username/modelorbital\n\nLet me know if you need help with anything else!\n</code></pre> <p>This looks great! We've successfully used Docker AI to create a new GitHub repository called \"modelorbital\" on your GitHub account.</p>"},{"location":"lab5/projects/Kubernetes-MCP/","title":"Kubernetes MCP Server and Claude","text":"<p>Imagine managing the Kubernetes clusters using simple natural language commands instead of memorizing dozens of kubectl incantations.  The Docker MCP (Model Context Protocol) Toolkit represents Docker's vision for a more integrated and accessible developer experience. It provides a comprehensive solution for managing Kubernetes through AI assistants with its Kubernetes MCP Server, which can be deployed in just 5 minutes.</p> <p>Before we begin, make sure you have the following requirements in place: Docker Desktop installed and running (the latest version is recommended)</p>"},{"location":"lab5/projects/Kubernetes-MCP/#step-1-enable-kubernetes-in-docker-desktop","title":"Step 1. Enable Kubernetes in Docker Desktop","text":""},{"location":"lab5/projects/Kubernetes-MCP/#step-2-setup-a-3-node-kind-cluster","title":"Step 2. Setup a 3-node Kind cluster","text":"<p>Select \u201cKind\u201d to set up a 3-node Kind cluster on the Docker Desktop.</p> <p></p>"},{"location":"lab5/projects/Kubernetes-MCP/#step-3-enable-kubernetes-mcp-server","title":"Step 3. Enable Kubernetes MCP Server","text":""},{"location":"lab5/projects/Kubernetes-MCP/#step-4-view-the-kubernetes-mcp-tools","title":"Step 4. View the Kubernetes MCP Tools","text":""},{"location":"lab5/projects/Kubernetes-MCP/#step-5-configure-the-claude-desktop","title":"Step 5. Configure the Claude Desktop","text":""},{"location":"lab5/projects/Kubernetes-MCP/#step-6-configure-mcp_docker-in-claude-desktop","title":"Step 6. Configure MCP_DOCKER in Claude Desktop","text":"<p>Open Claude Desktop and go to the \"Settings\" tab. You will see the following entry:</p> <p></p>"},{"location":"lab5/projects/Kubernetes-MCP/#step-7-verify-the-kubernetes-tools-under-claude-desktop","title":"Step 7. Verify the Kubernetes Tools under Claude Desktop","text":""},{"location":"lab5/projects/Kubernetes-MCP/#step-8-start-chatting-with-your-kubernetes-mcp-server","title":"Step 8. Start chatting with your Kubernetes MCP Server","text":""},{"location":"lab5/projects/Kubernetes-MCP/#prompt-1","title":"Prompt 1:","text":"<p>\"Create an Ngnix Pod in my Kubernetes cluster and list them in the tabular format\"</p> <p></p>"},{"location":"lab5/projects/postgres-mcp/","title":"Postgres mcp","text":""},{"location":"lab5/projects/postgres-mcp/#prerequisites","title":"Prerequisites","text":"<p>Before we start, make sure you have:</p> <ul> <li>Docker Desktop 4.41.0+ with the MCP Toolkit Extension installed</li> <li>Node.js (v18 or later) for running the frontend</li> <li>Claude Desktop installed</li> <li>Basic familiarity with Docker and JavaScript/TypeScript</li> <li>Basic SQL knowledge</li> </ul>"},{"location":"lab5/projects/postgres-mcp/#setting-up-the-sample-database","title":"Setting Up the Sample Database","text":"<p>Instead of using an empty Postgres database, let's use a real example with actual data.  We'll use a sample product catalog service:</p>"},{"location":"lab5/projects/postgres-mcp/#step-1-clone-the-sample-catalog-service","title":"Step 1. Clone the sample catalog service","text":"<pre><code>git clone https://github.com/ajeetraina/catalog-service-node\ncd catalog-service-node\n</code></pre>"},{"location":"lab5/projects/postgres-mcp/#step-2-start-the-backend-services-includes-postgres-with-sample-data","title":"Step 2. Start the backend services (includes Postgres with sample data)","text":"<pre><code>docker compose up -d --build\n</code></pre> <p>This will spin up:</p> <ul> <li>A Postgres database on port 5432 with sample catalog data</li> <li>A Node.js backend service</li> <li>Sample data including products, categories, and inventory</li> </ul> <p>Now let's bring up the frontend to see what data we're working with:</p>"},{"location":"lab5/projects/postgres-mcp/#step-3-install-frontend-dependencies","title":"Step 3. Install frontend dependencies","text":"<pre><code>npm install\n</code></pre>"},{"location":"lab5/projects/postgres-mcp/#step-4-start-the-development-server","title":"Step 4. Start the development server","text":"<pre><code>npm run dev\n</code></pre> <p>Open your browser to `http://localhost:5173 to see the catalog application.  This gives you a visual understanding of the data structure we'll be querying with Claude.</p> <p>Hit \"Create Product\" button and start adding the new items to your Product catalog system.</p> <p>Perfect! Now we have a realistic database to work with instead of an empty one.</p>"},{"location":"lab5/projects/postgres-mcp/#step-5-setting-up-mcp-toolkit","title":"Step 5. Setting up MCP Toolkit","text":"<p>Open Docker Desktop and navigate to the MCP Toolkit extension. Under \"MCP Server\", search for \"Postgres\" and select the Postgres MCP Server</p> <p></p>"},{"location":"lab5/projects/postgres-mcp/#step-6-configure-the-postgres-mcp-server","title":"Step 6. Configure the Postgres MCP Server","text":"<p>Click \"Configuration\" and add the right URL for your Postgres database:</p> <pre><code>postgresql://postgres:postgres@host.docker.internal:5432/catalog\n</code></pre> <p></p>"},{"location":"lab5/projects/postgres-mcp/#step-7-activate-the-postgres-mcp-server","title":"Step 7. Activate the Postgres MCP Server","text":"<p>Toggle the \"Enable\" switch to activate the Postgres MCP Server.</p>"},{"location":"lab5/projects/postgres-mcp/#step-8-configure-the-claude-desktop","title":"Step 8. Configure the Claude Desktop","text":""},{"location":"lab5/projects/postgres-mcp/#step-9-configure-mcp_docker-in-claude-desktop","title":"Step 9. Configure MCP_DOCKER in Claude Desktop","text":"<p>Open Claude Desktop and go to the \"Settings\" tab. You will see the following entry:</p> <ul> <li>Select Claude Settings</li> <li>Click on the Developer tab</li> <li>Click on the Edit Config button</li> <li>Add MCP_DOCKER to mcpServers section:</li> </ul> <pre><code>{\n  \"mcpServers\": {\n    \"MCP_DOCKER\": {\n      \"command\": \"docker\",\n      \"args\": [\n        \"run\",\n        \"-i\",\n        \"--rm\",\n        \"alpine/socat\",\n        \"STDIO\",\n        \"TCP:host.docker.internal:8811\"\n      ]\n    }\n  }\n}\n</code></pre>"},{"location":"lab5/projects/postgres-mcp/#step-10-restart-the-claude-desktop","title":"Step 10. Restart the Claude Desktop","text":""},{"location":"lab5/projects/postgres-mcp/#step-11-start-chatting-with-the-postgres-database","title":"Step 11. Start chatting with the Postgres Database","text":"<p>Prompt: </p> <pre><code>List out all the products in the catalog\n</code></pre> <p></p>"},{"location":"lab5/projects/postgres-vscode/","title":"Postgres vscode","text":""},{"location":"lab5/projects/postgres-vscode/#prerequisites","title":"Prerequisites","text":"<p>Before we start, make sure you have:</p> <ul> <li>Docker Desktop 4.41.0+ with the MCP Toolkit Extension installed</li> <li>Node.js (v18 or later) for running the frontend</li> <li>Claude Desktop installed</li> <li>Basic familiarity with Docker and JavaScript/TypeScript</li> <li>Basic SQL knowledge</li> </ul>"},{"location":"lab5/projects/postgres-vscode/#setting-up-the-sample-database","title":"Setting Up the Sample Database","text":"<p>Instead of using an empty Postgres database, let's use a real example with actual data.  We'll use a sample product catalog service:</p>"},{"location":"lab5/projects/postgres-vscode/#step-1-clone-the-sample-catalog-service","title":"Step 1. Clone the sample catalog service","text":"<pre><code>git clone https://github.com/ajeetraina/catalog-service-node\ncd catalog-service-node\n</code></pre>"},{"location":"lab5/projects/postgres-vscode/#step-2-start-the-backend-services-includes-postgres-with-sample-data","title":"Step 2. Start the backend services (includes Postgres with sample data)","text":"<pre><code>docker compose up -d --build\n</code></pre> <p>This will spin up:</p> <ul> <li>A Postgres database on port 5432 with sample catalog data</li> <li>A Node.js backend service</li> <li>Sample data including products, categories, and inventory</li> </ul> <p>Now let's bring up the frontend to see what data we're working with:</p>"},{"location":"lab5/projects/postgres-vscode/#step-3-install-frontend-dependencies","title":"Step 3. Install frontend dependencies","text":"<pre><code>npm install\n</code></pre>"},{"location":"lab5/projects/postgres-vscode/#step-4-start-the-development-server","title":"Step 4. Start the development server","text":"<pre><code>npm run dev\n</code></pre> <p>Open your browser to `http://localhost:5173 to see the catalog application.  This gives you a visual understanding of the data structure we'll be querying with Claude.</p> <p>Hit \"Create Product\" button and start adding the new items to your Product catalog system.</p> <p>Perfect! Now we have a realistic database to work with instead of an empty one.</p>"},{"location":"lab5/projects/postgres-vscode/#step-5-setting-up-mcp-toolkit","title":"Step 5. Setting up MCP Toolkit","text":"<p>Open Docker Desktop and navigate to the MCP Toolkit extension. Under \"MCP Server\", search for \"Postgres\" and select the Postgres MCP Server</p> <p></p>"},{"location":"lab5/projects/postgres-vscode/#step-6-configure-the-postgres-mcp-server","title":"Step 6. Configure the Postgres MCP Server","text":"<p>Click \"Configuration\" and add the right URL for your Postgres database:</p> <pre><code>postgresql://postgres:postgres@host.docker.internal:5432/catalog\n</code></pre> <p></p>"},{"location":"lab5/projects/postgres-vscode/#step-7-activate-the-postgres-mcp-server","title":"Step 7. Activate the Postgres MCP Server","text":"<p>Toggle the \"Enable\" switch to activate the Postgres MCP Server.</p>"},{"location":"lab5/projects/postgres-vscode/#step-8-configure-the-claude-desktop","title":"Step 8. Configure the Claude Desktop","text":""},{"location":"lab5/projects/postgres-vscode/#step-9-configure-mcp_docker-in-claude-desktop","title":"Step 9. Configure MCP_DOCKER in Claude Desktop","text":"<p>Open Claude Desktop and go to the \"Settings\" tab. You will see the following entry:</p> <ul> <li>Select Claude Settings</li> <li>Click on the Developer tab</li> <li>Click on the Edit Config button</li> <li>Add MCP_DOCKER to mcpServers section:</li> </ul> <pre><code>{\n  \"mcpServers\": {\n    \"MCP_DOCKER\": {\n      \"command\": \"docker\",\n      \"args\": [\n        \"run\",\n        \"-i\",\n        \"--rm\",\n        \"alpine/socat\",\n        \"STDIO\",\n        \"TCP:host.docker.internal:8811\"\n      ]\n    }\n  }\n}\n</code></pre>"},{"location":"lab5/projects/postgres-vscode/#step-10-restart-the-claude-desktop","title":"Step 10. Restart the Claude Desktop","text":""},{"location":"lab5/projects/postgres-vscode/#step-11-start-chatting-with-the-postgres-database","title":"Step 11. Start chatting with the Postgres Database","text":"<p>Prompt: </p> <pre><code>List out all the products in the catalog\n</code></pre> <p></p>"},{"location":"lab5/projects/visual-chatbot/","title":"Visual chatbot","text":""},{"location":"lab5/projects/visual-chatbot/#prerequisites","title":"Prerequisites","text":"<ul> <li>Install Docker Desktop 4.42.0 or later</li> <li>Enable Docker Model Runner in Docker Dashboard</li> <li>Enable the TCP host socket for DMR (use the default port of 12434)</li> <li>Download a model</li> </ul> <pre><code>doocker model pull ai/llama3.2:1B-Q8_0 \n</code></pre>"},{"location":"lab5/projects/visual-chatbot/#step-1-start-the-visual-chatbot-container","title":"Step 1. Start the visual chatbot container","text":"<pre><code>docker run -dp 3002:3000 -v /var/run/docker.sock:/var/run/docker.sock mikesir87/visual-chatbot\n</code></pre> <p>Did you notice that we're running the chatbot on port 3002?</p>"},{"location":"lab5/projects/visual-chatbot/#step-2-access-the-chatbot","title":"Step 2. Access the chatbot","text":"<p>Open your web browser and go to http://localhost:3002.</p>"},{"location":"lab5/projects/visual-chatbot/#step-3-choose-the-right-model-and-llm-backend","title":"Step 3. Choose the right model and LLM Backend","text":"<p>For this demo, select the following options:</p> <ul> <li>Docker Model Runner</li> <li>Model: <code>ai/llama3.2:1B-Q8_0</code></li> </ul> <p>Click \"Save\" to apply the settings.</p> <p>The system prompt currently indicates the LLM should act as a whimsical guide.  This suggests it will be fun and probably use lots of emojis!</p>"},{"location":"lab5/projects/visual-chatbot/#step-4-ask-what-it-can-do","title":"Step 4. Ask what it can do","text":"<p>Enter a prompt asking \"Hello! What can you do for me today?\"</p> <p></p> <p>Note that the app does not stream the responses, so it may take a little while to get the response.  So, try to stall for time a bit (without revealing it's all running locally).</p> <p>Hooray! We have a message!</p>"},{"location":"lab5/projects/visual-chatbot/#step-5-click-the-response-to-see-the-message","title":"Step 5. Click the response to see the message","text":"<p>Clicking on a message will provide the details of that message, which came directly from the LLM and will go back in the next API request.</p> <p></p>"},{"location":"lab5/projects/visual-chatbot/#step-6-change-the-system-prompt","title":"Step 6. Change the system prompt","text":"<p>Go to <code>Settings -&gt; System prompt</code> and change the prompt to be the <code>\"Grumpy old man\"</code>.</p> <p></p> <p>Before submitting, enable the <code>\"replay messages\"</code>. Then, press <code>save</code>.</p>"},{"location":"lab5/projects/visual-chatbot/#step-7-notice-the-very-different-persona","title":"Step 7. Notice the very different persona","text":"<p>Highlight the much shorter and direct response from the LLM now. At the end of the day, it's the same model, but with a very different set of instructions.</p> <p>This starts to introduce prompt engineering and how it's important to set the rules and the persona for the LLM. Again, normally, this is done by the GenAI application and not something an end user can change.</p>"},{"location":"lab5/projects/visual-chatbot/#interact-with-the-llm-for-the-real-time-information","title":"Interact with the LLM for the real-time information","text":"<p>Reset all the messages by clicking on the \"Reset messages\" button in the top right corner of the chat window.</p> <p>Let's ask the LLM what time it is in New York.</p> <p>Enter a prompt asking \"What time is it in New York now?\"</p> <p></p>"},{"location":"lab5/projects/visual-chatbot/#step-8-adding-time-tool","title":"Step 8. Adding Time Tool","text":"<p>Click \"Add Time tool\" to add a tool that will provide the current time in New York.</p> <p></p>"},{"location":"lab5/projects/visual-chatbot/#step-9-ask-the-llm-again","title":"Step 9. Ask the LLM again","text":"<p>Now, ask the LLM again \"What time is it in New York now?\".</p> <p></p>"},{"location":"lab5/projects/visual-chatbot/mcp/","title":"Running your First MCP Server","text":""},{"location":"lab5/projects/visual-chatbot/mcp/#prerequisites","title":"Prerequisites","text":"<ul> <li>Node.js installed (version 18 or higher recommended)</li> <li>npm or yarn package manager</li> </ul>"},{"location":"lab5/projects/visual-chatbot/mcp/#create-a-directory","title":"Create a directory","text":"<p>Create a new directory called mcptooling</p> <pre><code>mkdir mcptooling\n</code></pre>"},{"location":"lab5/projects/visual-chatbot/mcp/#package-depdendencies","title":"Package Depdendencies","text":"<p>Install the required packages:</p> <pre><code>npm install @modelcontextprotocol/sdk zod\n</code></pre>"},{"location":"lab5/projects/visual-chatbot/mcp/#execution-steps","title":"Execution Steps","text":"<p>Save the code to a file (e.g., time-server.js)</p> <pre><code>import { McpServer } from \"@modelcontextprotocol/sdk/server/mcp.js\";\nimport { StdioServerTransport } from \"@modelcontextprotocol/sdk/server/stdio.js\";\nimport { z } from \"zod\";\n\nconst server = new McpServer({ name: \"Time\", version: \"1.0.0\" });\n\nserver.tool(\n  \"get-current-time\",\n  \"Get the current time for a requested timezone\",\n  { \n    timezone: z.string().describe(\"The requested timezone in IANA format\"),\n  },\n  async ({ timezone }) =&gt; {\n    const time = new Date().toLocaleString(\"en-US\", { timeZone: timezone });\n\n    return {\n      content: [{\n        type: \"text\",\n        text: time,\n      }]\n    };\n  }\n);\n\nconst transport = new StdioServerTransport();\nawait server.connect(transport);\n</code></pre> <p>Save the code above to a file named <code>time-server.js</code> in the <code>mcptooling</code> directory.</p>"},{"location":"lab5/projects/visual-chatbot/mcp/#run-the-server","title":"Run the server:","text":"<p>Then, run the server using Node.js:</p> <pre><code>node time-server.js\n</code></pre>"},{"location":"lab5/projects/visual-chatbot/mcp/#what-this-server-does","title":"What this server does","text":"<p>This MCP server:</p> <ul> <li>Creates a tool called \"get-current-time\"</li> <li>Accepts a timezone parameter (in IANA format like \"America/New_York\")</li> <li>Returns the current time in that timezone</li> <li>Uses stdio transport (communicates via standard input/output)</li> </ul>"},{"location":"lab5/projects/visual-chatbot/mcp/#testing-the-server","title":"Testing the server","text":"<p>Since this uses stdio transport, you can test it by:</p> <ul> <li>Running it and sending JSON-RPC messages via stdin</li> <li>Or connecting it to an MCP client that supports stdio transport</li> <li>Or using it with applications that integrate MCP servers (like Claude Desktop, if configured)</li> </ul> <pre><code>node time-server.js\n</code></pre> <p>Great! Your MCP server is now running successfully. Since there's no output shown, that means it's working correctly and waiting for MCP protocol messages on stdin.</p>"},{"location":"lab5/projects/visual-chatbot/mcp/#method-1-test-with-a-simple-message","title":"Method 1: Test with a simple message","text":"<p>You can type this JSON-RPC message (press Enter after pasting):</p> <pre><code>{\"jsonrpc\": \"2.0\", \"id\": 1, \"method\": \"tools/list\"}\n</code></pre>"},{"location":"lab5/projects/visual-chatbot/mcp/#result","title":"Result","text":"<pre><code>{\"result\":{\"tools\":[{\"name\":\"get-current-time\",\"description\":\"Get the current time for a requested timezone\",\"inputSchema\":{\"type\":\"object\",\"properties\":{\"timezone\":{\"type\":\"string\",\"description\":\"The requested timezone in IANA format\"}},\"required\":[\"timezone\"],\"additionalProperties\":false,\"$schema\":\"http://json-schema.org/draft-07/schema#\"}}]},\"jsonrpc\":\"2.0\",\"id\":1}\n</code></pre>"},{"location":"lab5/projects/visual-chatbot/mcp/#method-2-test-the-time-tool","title":"Method 2: Test the time tool","text":"<p>You can test the \"get-current-time\" tool by sending a JSON-RPC message like this:</p> <pre><code>{\"jsonrpc\": \"2.0\", \"id\": 2, \"method\": \"tools/call\", \"params\": {\"name\": \"get-current-time\", \"arguments\": {\"timezone\": \"America/New_York\"}}}\n</code></pre> <p>You will receive a response with the current time in the specified timezone.</p> <pre><code>{\"result\":{\"content\":[{\"type\":\"text\",\"text\":\"5/31/2025, 10:29:05 PM\"}]},\"jsonrpc\":\"2.0\",\"id\":2}\n</code></pre>"},{"location":"lab5/projects/visual-chatbot/visual-chatbot/","title":"Getting Started","text":""},{"location":"lab5/projects/visual-chatbot/visual-chatbot/#prerequisites","title":"Prerequisites","text":"<ul> <li>Install Docker Desktop 4.41.0 or later</li> <li>Enable Docker Model Runner in Docker Dashboard</li> <li>Enable the TCP host socket for DMR (use the default port of 12434)</li> <li>Download a model</li> </ul> <pre><code>docker model pull ai/llama3.2:1B-Q8_0 \n</code></pre>"},{"location":"lab5/projects/visual-chatbot/visual-chatbot/#step-1-start-the-visual-chatbot-container","title":"Step 1. Start the visual chatbot container","text":"<pre><code>docker run -dp 3002:3000 -v /var/run/docker.sock:/var/run/docker.sock mikesir87/visual-chatbot\n</code></pre> <p>Did you notice that we're running the chatbot on port 3002?</p>"},{"location":"lab5/projects/visual-chatbot/visual-chatbot/#step-2-access-the-chatbot","title":"Step 2. Access the chatbot","text":"<p>Open your web browser and go to http://localhost:3002.</p>"},{"location":"lab5/projects/visual-chatbot/visual-chatbot/#step-3-choose-the-right-model-and-llm-backend","title":"Step 3. Choose the right model and LLM Backend","text":"<p>For this demo, select the following options:</p> <ul> <li>Docker Model Runner</li> <li>Model: <code>ai/llama3.2:1B-Q8_0</code></li> </ul> <p>Click \"Save\" to apply the settings.</p> <p>The system prompt currently indicates the LLM should act as a whimsical guide.  This suggests it will be fun and probably use lots of emojis!</p>"},{"location":"lab5/projects/visual-chatbot/visual-chatbot/#step-4-ask-what-it-can-do","title":"Step 4. Ask what it can do","text":"<p>Enter a prompt asking \"Hello! What can you do for me today?\"</p> <p></p> <p>Note that the app does not stream the responses, so it may take a little while to get the response.  So, try to stall for time a bit (without revealing it's all running locally).</p> <p>Hooray! We have a message!</p>"},{"location":"lab5/projects/visual-chatbot/visual-chatbot/#step-5-click-the-response-to-see-the-message","title":"Step 5. Click the response to see the message","text":"<p>Clicking on a message will provide the details of that message, which came directly from the LLM and will go back in the next API request.</p> <p></p>"},{"location":"lab5/projects/visual-chatbot/visual-chatbot/#step-6-change-the-system-prompt","title":"Step 6. Change the system prompt","text":"<p>Go to <code>Settings -&gt; System prompt</code> and change the prompt to be the <code>\"Grumpy old man\"</code>.</p> <p></p> <p>Before submitting, enable the <code>\"replay messages\"</code>. Then, press <code>save</code>.</p>"},{"location":"lab5/projects/visual-chatbot/visual-chatbot/#step-7-notice-the-very-different-persona","title":"Step 7. Notice the very different persona","text":"<p>Highlight the much shorter and direct response from the LLM now. At the end of the day, it's the same model, but with a very different set of instructions.</p> <p>This starts to introduce prompt engineering and how it's important to set the rules and the persona for the LLM. Again, normally, this is done by the GenAI application and not something an end user can change.</p>"},{"location":"lab5/projects/visual-chatbot/visual-chatbot/#interact-with-the-llm-for-the-real-time-information","title":"Interact with the LLM for the real-time information","text":"<p>Reset all the messages by clicking on the \"Reset messages\" button in the top right corner of the chat window.</p> <p>Let's ask the LLM what time it is in New York.</p> <p>Enter a prompt asking \"What time is it in New York now?\"</p> <p></p>"},{"location":"lab5/projects/visual-chatbot/visual-chatbot/#step-8-adding-time-tool","title":"Step 8. Adding Time Tool","text":"<p>Click \"Add Time tool\" to add a tool that will provide the current time in New York.</p> <p></p>"},{"location":"lab5/projects/visual-chatbot/visual-chatbot/#step-9-ask-the-llm-again","title":"Step 9. Ask the LLM again","text":"<p>Now, ask the LLM again \"What time is it in New York now?\".</p> <p></p>"},{"location":"prereq/prereq/","title":"Prerequisites","text":""},{"location":"prereq/prereq/#1-docker-desktop","title":"1. Docker Desktop","text":"<p>Download and Install Docker Desktop 4.42.0+ on your system. </p> <ul> <li>Apple Chip</li> <li>Intel Chip</li> <li>Windows with NVIDIA GPUs</li> <li>Linux</li> </ul>"},{"location":"prereq/prereq/#2-download-your-preferred-ides-optional","title":"2. Download your preferred IDEs (optional)","text":"<ul> <li>IntelliJ IDEA</li> <li>VS Code</li> </ul>"},{"location":"prereq/prereq/#3-access-to-the-repositories","title":"3. Access to the repositories","text":"<ul> <li>https://github.com/dockersamples/genai-model-runner-metrics</li> <li>https://github.com/ajeetraina/docker-workshop</li> </ul>"},{"location":"prereq/prereq/#4-enable-docker-model-runner","title":"4. Enable Docker Model Runner","text":"<pre><code>docker desktop enable model-runner\n</code></pre>"},{"location":"prereq/prereq/#5-download-the-models","title":"5. Download the models","text":"<p>Ensure that you have sufficient space to download these models on your Macbook.</p> <pre><code>docker model pull ai/llama3.2:1B-Q8_0\ndocker model pull ai/qwen3\ndocker model pull ai/gemma3\n</code></pre>"},{"location":"prereq/prereq/#5-download-the-following-images-from-the-docker-hub","title":"5. Download the following images from the Docker Hub","text":"<pre><code>docker pull grafana/grafana:10.1.0\ndocker pull jaegertracing/all-in-one:1.46\ndocker pull prom/prometheus:v2.45.0\n</code></pre>"},{"location":"prereq/prereq/#6-install-and-configure-your-preferred-mcp-client","title":"6. Install and configure your preferred MCP Client","text":"<pre><code>Ask Gordon\nClaude Desktop (optional)\nCursor (optional)\nContinue.dev (optional)\n</code></pre>"},{"location":"product-catalog/build/","title":"Build","text":""},{"location":"product-catalog/build/#using-docker-build-cloud","title":"Using Docker Build Cloud","text":"<p>Method: 1 : Running it locally</p> <pre><code>docker buildx create --driver cloud dockerdevrel/demo-builder\ndocker buildx build --builder cloud-dockerdevrel-demo-builder .\n</code></pre> <p></p> <p>Method:2 =- Running it using GitHub Workflow</p> <p>Open dockersamples/ repo and se the workflow.</p>"},{"location":"product-catalog/develop/","title":"Develop","text":""},{"location":"product-catalog/develop/#clone-the-repo","title":"Clone the repo","text":"<pre><code>git clone https://github.com/dockersamples/catalog-service-node\n</code></pre>"},{"location":"product-catalog/develop/#initial-setup","title":"Initial Setup","text":"<pre><code>cd demo/sdlc-e2e\n./setup.sh\n</code></pre> <p>The setup.sh script performs several important setup tasks to prepare the development environment for the Docker workshop. Let me explain what it does in detail: The script performs the following tasks:</p> <ul> <li>Creates a demo branch:</li> </ul> <p>It determines the repository root using git rev-parse --show-toplevel It creates a new git branch with a unique name combining \"demo\", the current date, and your username (e.g., demo-20250304-ajeet) This ensures each participant has their own isolated branch to work with</p> <ul> <li>Cleans the environment:</li> </ul> <p>Runs git clean -f to remove untracked files Deletes any existing branches named 'temp' or with the same demo branch name Creates a temporary branch, deletes the main branch locally, then recreates it This ensures everyone starts with a clean state</p> <ul> <li>Updates to latest code:</li> </ul> <p>Pulls the latest changes from the remote repository</p> <ul> <li>Applies the demo patch:</li> </ul> <p>Applies the demo.patch file using git apply --whitespace=fix This patch includes specific modifications to the codebase for the workshop In particular, it removes the upc: product.upc, line from src/services/ProductService.js (line 52) It also modifies the Dockerfile to use an older Node.js version and changes some package versions</p> <ul> <li>Creates a commit:</li> </ul> <p>Commits the changes with the message \"Demo prep\"</p> <ul> <li>Installs dependencies:</li> </ul> <p>Runs npm install to install all required Node.js dependencies</p> <ul> <li>Downloads container images:</li> </ul> <p>Runs docker compose pull to download all the required Docker images in advance This saves time during the workshop</p> <ul> <li>Prepares for Docker Build Cloud:</li> </ul> <p>Removes postgres:17.2 container image (if it exists) Creates and configures a cloud buildx builder for Docker Build Cloud This enables faster builds using Docker's cloud-based build infrastructure</p> <ul> <li>Configures Docker Scout:</li> </ul> <p>Sets up Docker Scout with the dockerdevrel organization This enables security scanning capabilities for the workshop</p> <p>In summary, the setup.sh script prepares a consistent, clean environment with all necessary dependencies, tools, and configurations so that workshop participants can immediately start working on the exercises without spending time on setup. It also makes deliberate modifications to the codebase (like removing the UPC field from Kafka messages) that will be \"fixed\" during the workshop exercises.</p>"},{"location":"product-catalog/develop/#run-the-compose","title":"Run the Compose","text":"<pre><code>docker compose up -d\n</code></pre>"},{"location":"product-catalog/develop/#setting-up-the-demo","title":"Setting up the Demo","text":"<p>Bring up the API service </p> <pre><code>npm install\nnpm run dev\n</code></pre>"},{"location":"product-catalog/develop/#accessing-the-web-client","title":"Accessing the Web Client","text":"<p>Open the web client (http://localhost:5173) and create a few products.</p>"},{"location":"product-catalog/develop/#accessing-the-database-visualizer","title":"Accessing the database visualizer","text":"<p>Open http://localhost:5050 and validate the products exist in the database.  \"Good! We see the UPCs are persisted in the database\"</p> <p>Use the following Postgres CLI to check if the products are added or not.</p> <pre><code># psql -U postgres\npsql (17.1 (Debian 17.1-1.pgdg120+1))\nType \"help\" for help\npostgres=# \\c catalog\nYou are now connected to database \"catalog\" as user \"postgres\".\ncatalog=# SELECT * FROM products;\n  1 | New Product | 100000000001 | 100.00 | f\n  2 | New Product | 100000000002 | 100.00 | f\n  3 | New Product | 100000000003 | 100.00 | f\n</code></pre>"},{"location":"product-catalog/develop/#access-the-kafka-visualizer","title":"Access the Kafka Visualizer","text":"<p>Before we access visualizer, let's apply the patch:</p> <p>Open the Kafka visualizer http://localhost:8080 and look at the published messages.  \"Ah! We see the messages don't have the UPC\"</p> <p></p>"},{"location":"product-catalog/develop/#lets-fix-it","title":"Let's fix it...","text":""},{"location":"product-catalog/develop/#configuring","title":"Configuring","text":"<p>In VS Code, open the <code>src/services/ProductService.js</code> file and add the following to the publishEvent on line ~52:</p> <pre><code>upc: product.upc,\n</code></pre> <p>Save the file and create a new product using the web UI. </p> <p></p> <p>Validate the message has the expected contents.</p>"},{"location":"product-catalog/overview/","title":"Catalog Service - Node","text":"<p>This repo is a demo project that demonstrates all of Docker's services in a single project. Specifically, it includes the following:</p> <ul> <li>A containerized development environment (in a few varieties of setup)</li> <li>Integration testing with Testcontainers</li> <li>Building in GitHub Actions with Docker Build Cloud</li> </ul> <p>This project is also setup to be used for various demos. </p>"},{"location":"product-catalog/prereq/","title":"Prereq","text":""},{"location":"product-catalog/prereq/#1-docker-desktop","title":"1. Docker Desktop","text":"<p>Download and Install Docker Desktop on your system. Make sure you are using Docker Desktop v4.27.2 and above.</p> <ul> <li>Apple Chip</li> <li>Intel Chip</li> <li>Windows</li> <li>Linux</li> </ul>"},{"location":"product-catalog/prereq/#enabling-wsl-2-based-engine-on-docker-desktop-for-windows","title":"Enabling WSL 2 based engine on Docker Desktop for Windows","text":"<p>In case you're using Windows 11, you will need to enable WSL 2 by opening Docker Desktop &gt; Settings &gt; Resources &gt; WSL Integration</p> <p></p>"},{"location":"product-catalog/prereq/#2-install-nodejs","title":"2. Install Nodejs","text":"<p>To demonstrate the Product Catalog sample app, you will require Node 22+ version installed on your system.</p> <p>Note: You must download and install the Node pre-built installer on your local system to get the npm install command to work seamlessly. Click here to download</p>"},{"location":"product-catalog/prereq/#3-access-to-the-repositories","title":"3. Access to the repositories","text":"<ul> <li>https://github.com/dockersamples/catalog-service-node </li> </ul>"},{"location":"product-catalog/prereq/#4-access-to-the-list-of-packages","title":"4. Access to the list of Packages","text":"<p>If you're behind the firewall, these are the list of packages required for this workshop:</p>"},{"location":"product-catalog/prereq/#docker-init-demo","title":"Docker Init Demo","text":"<pre><code>alpine-baselayout-3.6.5-r0\nalpine-baselayout-data-3.6.5-r0\nalpine-keys-2.4-r1\napk-tools-2.14.4-r0\nbusybox-1.36.1-r29\nbusybox-binsh-1.36.1-r29\nca-certificates-bundle-20240705-r0\nlibcrypto3-3.3.2-r0\nlibgcc-13.2.1_git20240309-r0\nlibssl3-3.3.2-r0\nlibstdc++-13.2.1_git20240309-r0\nmusl-1.2.5-r0\nmusl-utils-1.2.5-r0\nscanelf-1.3.7-r2\nssl_client-1.36.1-r29\nzlib-1.3.1-r1\n</code></pre>"},{"location":"product-catalog/prereq/#install-testcontainers-desktop-app","title":"Install Testcontainers Desktop App","text":"<p>Click here to download Testcontainers Desktop app and install it on your machine.</p>"},{"location":"product-catalog/secure/","title":"Secure","text":""},{"location":"product-catalog/secure/#using-docker-scout","title":"Using Docker Scout","text":"<pre><code>docker build -t newcatalog .\n</code></pre>"},{"location":"product-catalog/secure/#apply-the-patches","title":"Apply the patches","text":"<pre><code>patch -p1 &lt; /demo/scout.patch\n</code></pre>"},{"location":"product-catalog/tech-stack/","title":"Tech stack","text":""},{"location":"product-catalog/tech-stack/#application-architecture","title":"Application architecture","text":"<p>This sample app provides an API that utilizes the following setup:</p> <ul> <li>Data is stored in a PostgreSQL database</li> <li>Product images are stored in a AWS S3 bucket</li> <li>Inventory data comes from an external inventory service</li> <li>Updates to products are published to a Kafka cluster</li> </ul> <p></p> <p>During development, containers provide the following services:</p> <ul> <li>PostgreSQL and Kafka runs directly in a container</li> <li>LocalStack is used to run S3 locally</li> <li>WireMock is used to mock the external inventory service</li> <li>pgAdmin and kafbat are added to visualize the PostgreSQL database and Kafka cluster</li> </ul> <p></p>"},{"location":"product-catalog/test/","title":"Testing Your Containerized Application","text":"<p>In this section, you'll learn how to implement and run automated tests for your containerized application using Testcontainers. This approach ensures that your tests run in an environment that closely matches production, leading to more reliable test results.</p>"},{"location":"product-catalog/test/#understanding-testcontainers","title":"Understanding Testcontainers","text":"<p>Testcontainers is a library that provides lightweight, throwaway instances of common databases, message brokers, or anything else that can run in a Docker container. It's perfect for integration testing because:</p> <ul> <li>It creates isolated environments for each test</li> <li>It spins up actual services rather than mocks (when needed)</li> <li>It cleans up automatically after tests complete</li> <li>It's language-agnostic (though we'll use the JavaScript implementation)</li> </ul>"},{"location":"product-catalog/test/#prerequisites","title":"Prerequisites","text":"<p>Before running the tests, ensure you have:</p> <ul> <li>Docker Desktop installed and running</li> <li>Testcontainers Desktop installed (optional but recommended)</li> <li>Completed the Development phase</li> </ul>"},{"location":"product-catalog/test/#setting-up-testcontainers-desktop-optional","title":"Setting Up Testcontainers Desktop (Optional)","text":"<ol> <li>Download and install Testcontainers Desktop</li> <li>Open the application</li> <li>Ensure it can connect to your Docker instance</li> </ol> <p>Testcontainers Desktop provides a visual interface for monitoring containers created during testing.</p>"},{"location":"product-catalog/test/#understanding-the-test-structure","title":"Understanding the Test Structure","text":"<p>Our application uses two types of tests:</p> <ol> <li>Unit Tests: Test individual functions without external dependencies</li> <li>Integration Tests: Test complete features with actual dependencies (using Testcontainers)</li> </ol> <p>The test files are located in: - <code>test/src/unit/</code> - Unit tests - <code>test/src/integration/</code> - Integration tests</p> <p>Key integration test files: - <code>containerSupport.js</code>: Manages container lifecycle for tests - <code>kafkaSupport.js</code>: Provides Kafka testing utilities - <code>productCreation.integration.test.js</code>: Tests product creation functionality</p>"},{"location":"product-catalog/test/#running-the-tests","title":"Running the Tests","text":""},{"location":"product-catalog/test/#unit-tests","title":"Unit Tests","text":"<p>To run the unit tests:</p> <pre><code>npm run unit-test\n</code></pre> <p>These tests verify the behavior of individual functions without external dependencies.</p>"},{"location":"product-catalog/test/#integration-tests","title":"Integration Tests","text":"<p>To run the integration tests:</p> <pre><code>npm run integration-test\n</code></pre> <p>When you run integration tests, Testcontainers will: 1. Spin up required containers (PostgreSQL, Kafka, LocalStack) 2. Run the tests against these containers 3. Tear down the containers when tests complete</p> <p>You can observe these containers in Docker Desktop or Testcontainers Desktop:</p> <p></p>"},{"location":"product-catalog/test/#understanding-the-integration-test-code","title":"Understanding the Integration Test Code","text":"<p>Let's examine the key components of the integration test:</p>"},{"location":"product-catalog/test/#container-setup","title":"Container Setup","text":"<pre><code>// From containerSupport.js\nasync function setup() {\n  // Start PostgreSQL container\n  postgres = await new GenericContainer(\"postgres:15\")\n    .withExposedPorts(5432)\n    .withEnvironment({ POSTGRES_PASSWORD: \"postgres\" })\n    .start();\n\n  // Start Kafka container\n  kafka = await new GenericContainer(\"confluentinc/cp-kafka:7.4.0\")\n    .withExposedPorts(9092)\n    .withEnvironment({\n      KAFKA_ADVERTISED_LISTENERS: \"PLAINTEXT://localhost:9092\",\n      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1\n    })\n    .start();\n\n  // Start LocalStack (for S3)\n  localstack = await new GenericContainer(\"localstack/localstack:2.2\")\n    .withExposedPorts(4566)\n    .start();\n\n  // Configure environment variables for tests\n  process.env.DATABASE_URL = `postgres://postgres:postgres@localhost:${postgres.getMappedPort(5432)}/postgres`;\n  process.env.KAFKA_BROKER = `localhost:${kafka.getMappedPort(9092)}`;\n  process.env.S3_ENDPOINT = `http://localhost:${localstack.getMappedPort(4566)}`;\n}\n</code></pre> <p>This code sets up isolated containers for each service our application depends on.</p>"},{"location":"product-catalog/test/#test-cases","title":"Test Cases","text":"<pre><code>// From productCreation.integration.test.js\ndescribe(\"Product creation\", () =&gt; {\n  it(\"should publish and return a product when creating a product\", async () =&gt; {\n    const product = {\n      name: \"Test Product\",\n      upc: \"123456789012\",\n      price: 9.99\n    };\n\n    const createdProduct = await productService.createProduct(product);\n\n    expect(createdProduct.id).toBeDefined();\n    expect(createdProduct.name).toBe(product.name);\n    expect(createdProduct.upc).toBe(product.upc);\n    expect(createdProduct.price).toBe(product.price);\n\n    const retrievedProduct = await productService.getProduct(createdProduct.id);\n    expect(retrievedProduct).toEqual(createdProduct);\n  });\n\n  it(\"should publish a Kafka message when creating a product\", async () =&gt; {\n    const product = {\n      name: \"Kafka Test Product\",\n      upc: \"123456789013\",\n      price: 19.99\n    };\n\n    await productService.createProduct(product);\n\n    const message = await kafkaConsumer.waitForMessage(\"products\", 5000);\n    expect(message).toBeDefined();\n    expect(message.action).toBe(\"product_created\");\n    expect(message.name).toBe(product.name);\n    expect(message.upc).toBe(product.upc);\n    expect(message.price).toBe(product.price);\n  });\n\n  // Additional tests...\n});\n</code></pre> <p>These tests verify that: 1. Products can be created and retrieved 2. Kafka messages are published correctly 3. File uploads work as expected 4. Business rules (like preventing duplicate UPCs) are enforced</p>"},{"location":"product-catalog/test/#benefits-of-testcontainers-for-integration-testing","title":"Benefits of Testcontainers for Integration Testing","text":"<ol> <li>Realistic Testing: Tests run against actual services, not mocks</li> <li>Isolation: Each test run gets fresh containers</li> <li>Portability: Tests run the same way on any machine with Docker</li> <li>Parallelism: Tests can run in parallel with isolated containers</li> <li>CI/CD Compatibility: Works well in CI/CD pipelines</li> </ol>"},{"location":"product-catalog/test/#common-testing-patterns-with-containers","title":"Common Testing Patterns with Containers","text":"<ol> <li>Database Testing: Use a containerized database with a known schema and test data</li> <li>Message Queue Testing: Verify message publishing and consuming with real message brokers</li> <li>API Testing: Test API endpoints against containerized dependencies</li> <li>End-to-End Testing: Use containers for all services to test complete workflows</li> </ol>"},{"location":"product-catalog/test/#troubleshooting","title":"Troubleshooting","text":"<p>If you encounter issues with Testcontainers:</p> <ol> <li>Port Conflicts: Ensure no other services are using the same ports</li> <li>Docker Connection: Verify Docker is running and accessible</li> <li>Resource Limits: Check if Docker has sufficient resources (CPU, memory)</li> <li>Network Issues: Ensure containers can communicate with each other</li> </ol>"},{"location":"product-catalog/test/#next-steps","title":"Next Steps","text":"<p>Now that you've learned how to test your application with Testcontainers, you can:</p> <ol> <li>Add more tests to improve coverage</li> <li>Integrate tests into your CI/CD pipeline</li> <li>Move on to the Build phase to learn how to build and package your application for deployment</li> </ol>"}]}